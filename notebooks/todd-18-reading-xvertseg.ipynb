{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading xVertSeg\n",
    "\n",
    "First contact with the data in code.  Read the files.  Create metadata about xvertseg scans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, Concatenate, Add)\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "importlib.reload(util)\n",
    "import preprocessing\n",
    "importlib.reload(preprocessing)\n",
    "import datagen\n",
    "importlib.reload(datagen)\n",
    "import modelutil\n",
    "importlib.reload(modelutil)\n",
    "\n",
    "SEED = 0\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1\n",
    "PATCH_SHAPE = (32, 32, 32)\n",
    "\n",
    "MODEL_NAME = 'model_09'\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "PP_XVERTSEG_IMG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_LOG_DIR = PROJECT_DATA_DIR / 'tensorboard' / MODEL_NAME\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_LOG_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_IMG_DIR, PP_XVERTSEG_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "\n",
    "def get_mhd_raw_id(d):\n",
    "    '''\n",
    "    d: a Path, a directory containing paired MetaImage format files.\n",
    "    returns a triple of a list of mhd files, of raw files, and of xvertseg scan ids.\n",
    "    '''\n",
    "        \n",
    "    mhds = [str(p) for p in list(d.glob('*.mhd'))]\n",
    "    ids = [int(re.search(r'.*?(\\d\\d\\d)\\.mhd$', p).group(1)) for p in mhds]\n",
    "    raws = [d / re.sub(r'\\.mhd$', '.raw', p) for p in mhds]\n",
    "    return mhds, raws, ids\n",
    "\n",
    "\n",
    "def get_xvertseg_infos(xvertseg_dir):\n",
    "    '''\n",
    "    Build a dataframe with columns: id, dataset, image_mhd, image_raw, mask_mhd, mask_raw, and labeled.\n",
    "    id is the number embedded in the xvertseg filenames.  xvertseg is split into 2 datasets, data1 and data2.\n",
    "    data1 is labeled, meaning it has segmentation masks.  data2 only has images.\n",
    "    \n",
    "    There are 15 labeled images and 10 unlabeled images.\n",
    "    \n",
    "    data_dir: the xVertSeg1.v1/Data1 dir, as a Path.\n",
    "    return: dataframe. \n",
    "    '''\n",
    "    # filename examples\n",
    "    # image016.mhd\n",
    "    # image016.raw\n",
    "    # mask001.mhd\n",
    "    # mask001.raw\n",
    "    \n",
    "    # Data1 has 15 images and masks (labeled data)\n",
    "    # Data2 has 10 test images with no mask.  Unlabeled data.\n",
    "    data1_dir = xvertseg_dir / 'Data1'\n",
    "    idir1 = data1_dir / 'images'\n",
    "    mdir1 = data1_dir / 'masks'\n",
    "    data2_dir = xvertseg_dir / 'Data2'\n",
    "    idir2 = data2_dir / 'images'\n",
    "    \n",
    "    img1_mhds, img1_raws, img1_ids = get_mhd_raw_id(idir1)\n",
    "    img1_df = pd.DataFrame({'id': img1_ids, 'image_mhd': img1_mhds, 'image_raw': img1_raws})\n",
    "    mask1_mhds, mask1_raws, mask1_ids = get_mhd_raw_id(mdir1)\n",
    "    mask1_df = pd.DataFrame({'id': mask1_ids, 'mask_mhd': mask1_mhds, 'mask_raw': mask1_raws})\n",
    "    img2_mhds, img2_raws, img2_ids = get_mhd_raw_id(idir2)\n",
    "    img2_df = pd.DataFrame({'id': img2_ids, 'image_mhd': img2_mhds, 'image_raw': img2_raws})\n",
    "    img2_df['dataset'] = ['data2'] * len(img2_df)\n",
    "    \n",
    "    df = img1_df.merge(mask1_df, on='id')\n",
    "    df['dataset'] = ['data1'] * len(df)\n",
    "    df = pd.concat([df, img2_df]).sort_values('id').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_xvertseg_infos(XVERTSEG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xvertseg_img(path):\n",
    "    # https://github.com/juliandewit/kaggle_ndsb2017/blob/master/step1_preprocess_luna16.py\n",
    "    itk = SimpleITK.ReadImage(path)\n",
    "    img = SimpleITK.GetArrayFromImage(itk)\n",
    "    return img, itk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at an image and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, itk = load_xvertseg_img(df.loc[0, 'image_mhd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.animate_crop(img, crop=(0.0, 1, 0.5, 0.8, 0.3, 0.6), step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, mitk = load_xvertseg_img(df.loc[0, 'mask_mhd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.animate_crop(mask, crop=(0.0, 1, 0.5, 0.8, 0.3, 0.6), step=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at mask\n",
    "\n",
    "The mask has 6 unique values: 0, 200, 210, 220, 230, 240.  These correspond to background and the vertebrae l1, l2, ..., l5, I think.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mask.ravel())\n",
    "plt.show()\n",
    "# looks like a typical ct scan in hounsfield units...or does it?  No -1000 values?  Looks like the units are hounsfield + 1000.\n",
    "plt.hist(img.ravel(), bins=50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
