{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 10: Denoising Autoencoder\n",
    "\n",
    "Play with Gaussian Noise and Dropout in autoencoder.  Taking a brief break from xVertSeg to explore some ideas at our final presentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, Concatenate, Add,\n",
    "                          GaussianNoise, Dropout\n",
    "                         )\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK # xvertseg MetaImage files\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "import preprocessing\n",
    "import datagen\n",
    "import modelutil\n",
    "import xvertseg\n",
    "\n",
    "\n",
    "MODEL_NAME = 'model_10'\n",
    "SEED = 25 # random seed\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SHAPE = (32, 32, 32)\n",
    "VALIDATION_SPLIT = 0.25\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "# UVMMC\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "# xVertSeg\n",
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "PP_XVERTSEG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_MD_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_LOG_DIR = PROJECT_DATA_DIR / 'tensorboard' / MODEL_NAME\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_LOG_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_DIR, PP_XVERTSEG_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# I love u autoreload!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, val_gen = datagen.get_nifti_datagens(\n",
    "    preprocessed_metadata_path=PP_MD_PATH, batch_size=BATCH_SIZE, seed=SEED, validation_split=VALIDATION_SPLIT,\n",
    "    crop_shape=PATCH_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "\n",
    "Downsampled agressively with strided convolutions to fit in memory.  Residual blocks.  Global pooling at the end to classify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def downsampling_block(x, n_a, dropout=None):\n",
    "    x = Dropout(rate=dropout)(x)\n",
    "    x = MaxPooling3D(padding='same')(x)\n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def upsampling_block(x, n_a, dropout=None):\n",
    "    x = Dropout(rate=dropout)(x)\n",
    "    x = UpSampling3D()(x) # dropout dimming?\n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "    \n",
    "def residual_block(x, n_a, dropout=None):\n",
    "    '''\n",
    "    n_l: number of layers/convolutions in the residual path.\n",
    "    '''\n",
    "    x_i = x # initial x\n",
    "    if dropout is not None:\n",
    "        x = Dropout(rate=dropout)(x)\n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x)        \n",
    "    x = Add()([x_i, x])  \n",
    "    return x\n",
    "\n",
    "    \n",
    "def build_model(input_shape, n_a=16, n_r=8, n_d=3, dropout=None, noise=None):\n",
    "    '''\n",
    "    3D convolutional encoder-decoder autoencoder.\n",
    "    3 poolings reduce input from shape to 1/512th the original size.\n",
    "    Channel depth increases to 8 * n_a\n",
    "    a very respectable compression factor.\n",
    "    \n",
    "    dropout: proportion of activation of input to drop out. 0.0 to 1.0\n",
    "    noise: std dev of noise added to input activation.\n",
    "    returns: model\n",
    "    '''\n",
    "\n",
    "    x_input = Input(shape=input_shape)\n",
    "    x = x_input\n",
    "    \n",
    "    # noise regularization\n",
    "    if noise: \n",
    "        x = GaussianNoise(stddev=noise)(x)\n",
    "\n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x)\n",
    "\n",
    "    # dropout, maxpool, conv, conv\n",
    "    for d in range(1, n_d+1):\n",
    "        x = downsampling_block(x, n_a=n_a*(2**d), dropout=dropout)\n",
    "\n",
    "    # residual: dropout, conv, conv\n",
    "    for r in range(n_r):\n",
    "        x = residual_block(x, n_a=n_a*(2**n_d), dropout=dropout)\n",
    "        \n",
    "    # dropout, upsampling, conv, conv\n",
    "    for d in range(n_d, 0, -1):\n",
    "        x = upsampling_block(x, n_a=n_a*(2**(d-1)), dropout=dropout)\n",
    "\n",
    "    y = Conv3D(1, kernel_size=(1, 1, 1), activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=y)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 16 # base number of channels.\n",
    "n_r = 8 # number of residual blocks\n",
    "n_d = 3 # number of downsamplings.  aka depth.\n",
    "dropout = 0.2 # dropout rate\n",
    "noise = 0.003 # input gaussian noise std dev\n",
    "model = build_model(input_shape=PATCH_SHAPE + (1,), n_a=12, n_r=4, n_d=3, dropout=dropout, noise=noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model\n",
    "\n",
    "Training has callbacks to save model every epoch, to log performance stats every epoch to a csv file and tensorboard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, log_path = modelutil.train_model(\n",
    "    model, train_gen, val_gen, epochs=100, batch_size=BATCH_SIZE, models_dir=MODELS_DIR, model_name=MODEL_NAME, \n",
    "    log_dir=LOG_DIR, tensorboard_log_dir=TENSORBOARD_LOG_DIR, max_queue_size=20, use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metrics from the log file\n",
    "log_path = sorted(LOG_DIR.glob(f'{MODEL_NAME}*_log.csv'), reverse=True)[0]\n",
    "print('most recent log_path:', log_path)\n",
    "metrics = pd.read_csv(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([metrics[::10], metrics[-1:]])) # every 10th metric and the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy \n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,1.0]) # Show results on 0..1 range\n",
    "plt.plot(metrics[\"acc\"])\n",
    "plt.plot(metrics[\"val_acc\"])\n",
    "plt.legend(['Training Accuracy', \"Validation Accuracy\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.plot(metrics[\"loss\"])\n",
    "plt.plot(metrics[\"val_loss\"])\n",
    "plt.legend(['Training Loss', \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easier to see on tensorboard the validation loss is still dropping, slightly, maybe, compared to model 4, where validation loss is climbing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Effect of Autoencoder Training\n",
    "\n",
    "Use models from different training epochs to encode images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viz in modelutil.vizualize_predictions_by_epochs(MODELS_DIR, MODEL_NAME, [1, EPOCHS//10, EPOCHS], train_gen, val_gen, step=1):\n",
    "    display(viz)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
