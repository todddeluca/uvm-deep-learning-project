{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "- gray value augmentation\n",
    "- flips, rotations, scaling.\n",
    "- random crops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, Concatenate, Add,\n",
    "                          GaussianNoise, Dropout\n",
    "                         )\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK # xvertseg MetaImage files\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import augmentation\n",
    "import util\n",
    "import preprocessing\n",
    "import datagen\n",
    "import modelutil\n",
    "import xvertseg\n",
    "\n",
    "\n",
    "MODEL_NAME = 'model_14'\n",
    "SEED = 25 # random seed\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SHAPE = (32, 32, 32)\n",
    "VALIDATION_SPLIT = 0.25\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "# UVMMC\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "# xVertSeg\n",
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "PP_XVERTSEG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_MD_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_LOG_DIR = PROJECT_DATA_DIR / 'tensorboard' / MODEL_NAME\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_LOG_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_DIR, PP_XVERTSEG_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# I love u autoreload!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gray Value Augmentation\n",
    "\n",
    "Increase all the values in the image by a random proportion.  This lightens or darkens the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = preprocessing.read_preprocessed_metadata(PP_MD_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = infos.loc[12, 'pp_path']\n",
    "img = preprocessing.get_preprocessed_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('img shape:', img.shape)\n",
    "util.animate_crop(img, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    aug = augmentation.augment_image(img, gray_std=0.25, crop_shape=(128, 128, 128), gray_disco=True)\n",
    "    print('augmented shape:', aug.shape)\n",
    "    display(util.animate_crop(aug, step=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flip Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    aug = augmentation.augment_image(img, flip=0.5)\n",
    "    print('augmented shape:', aug.shape)\n",
    "    display(util.animate_crop(aug, step=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposition Augmentation\n",
    "\n",
    "Transpose the axes.  Like flipping along a diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    aug = augmentation.augment_image(img, crop_shape=(128,)*3, transpose=True)\n",
    "    print('augmented shape:', aug.shape)\n",
    "    display(util.animate_crop(aug, step=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
