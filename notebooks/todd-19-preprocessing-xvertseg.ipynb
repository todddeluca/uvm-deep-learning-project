{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing xVertSeg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, Concatenate, Add)\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK # xvertseg MetaImage files\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "import preprocessing\n",
    "import datagen\n",
    "import modelutil\n",
    "import xvertseg\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1\n",
    "PATCH_SHAPE = (32, 32, 32)\n",
    "\n",
    "MODEL_NAME = 'model_10'\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "# UVMMC\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "# xVertSeg\n",
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "PP_XVERTSEG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_MD_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_LOG_DIR = PROJECT_DATA_DIR / 'tensorboard' / MODEL_NAME\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_LOG_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_DIR, PP_XVERTSEG_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# I love u autoreload!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = xvertseg.get_xvertseg_infos(XVERTSEG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, itk = xvertseg.load_xvertseg_img(infos.loc[0, 'image_mhd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, mitk = xvertseg.load_xvertseg_img(infos.loc[0, 'mask_mhd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_xvertseg_image(image):\n",
    "    '''\n",
    "    img: an xvertseg xyz oriented image.  These images look like they have hounsfield units shifted by +1000 so\n",
    "    that they will be non-negative numbers.  Anyway...\n",
    "    \n",
    "    Normalize each voxel in img by clipping values to lie within 0 to 2000.  \n",
    "    Scale the numbers to between 0 and 1.\n",
    "    \n",
    "    return: normalized image.\n",
    "    '''\n",
    "    MIN_BOUND = 0000.0 # Air: -1000, Water: 0 hounsfield units.\n",
    "    MAX_BOUND = 2000.0 # Bone: 200, 700, 3000.  https://en.wikipedia.org/wiki/Hounsfield_scale\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image > 1] = 1.\n",
    "    image[image < 0] = 0.\n",
    "    return image\n",
    "\n",
    "\n",
    "def plot_image_historgrams():\n",
    "    infos = get_xvertseg_infos(XVERTSEG_DIR)\n",
    "    for i in range(len(infos)):\n",
    "        img_zyx, itk = load_xvertseg_img(infos.loc[i, 'image_mhd'])\n",
    "        img = np.swapaxes(img_zyx, 0, 2) # swap z and x.\n",
    "        plt.hist(img.ravel(), 256)\n",
    "        plt.title('image histogram for id ' + str(infos.loc[i, 'id']))\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of voxel values.  Does it look like hounsfield units.  Yes, but shifted.\n",
    "# infos = xvertseg.get_xvertseg_infos(PP_XVERTSEG_MD_PATH)\n",
    "infos = xvertseg.read_xvertseg_metadata(PP_XVERTSEG_MD_PATH)\n",
    "plt.hist(img.ravel())\n",
    "plt.title('infos' + str(infos.loc[0, 'id']))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the other images.\n",
    "# This takes a few minutes.\n",
    "xvertseg.plot_image_historgrams()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of voxel values.  Does it look like hounsfield units.  Yes, but shifted.\n",
    "plt.hist(normalize_xvertseg_image(img).ravel(), bins=256)\n",
    "plt.title('infos' + str(infos.loc[0, 'id']))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/juliandewit/kaggle_ndsb2017/blob/master/step1_preprocess_luna16.py\n",
    "\n",
    "\n",
    "def get_preprocessed_xvertseg_image_path(id, preprocessed_dir):\n",
    "    return str(Path(preprocessed_dir, f'image{id:03}.npy'))\n",
    "\n",
    "\n",
    "def get_preprocessed_xvertseg_binary_mask_path(id, preprocessed_dir):\n",
    "    return str(Path(preprocessed_dir, f'binmask{id:03}.npy'))\n",
    "\n",
    "\n",
    "def get_preprocessed_xvertseg_categorical_mask_path(id, preprocessed_dir):\n",
    "    return str(Path(preprocessed_dir, f'catmask{id:03}.npy'))\n",
    "\n",
    "\n",
    "def resample_xvertseg_image(img, spacing, target_spacing, metadata_only=False):\n",
    "\n",
    "    print('img shape:', img.shape)\n",
    "    print('img spacing:', spacing)\n",
    "    print('target spacing:', target_spacing)\n",
    "    # resample image\n",
    "    resampled_img, resampled_spacing = preprocessing.resample_image(img, spacing, target_spacing,\n",
    "                                                                    metadata_only=metadata_only)\n",
    "    print('resampled image spacing:', resampled_spacing)\n",
    "    print('resampled image shape:', resampled_img.shape)\n",
    "    return resampled_img, resampled_spacing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = xvertseg.get_xvertseg_infos(XVERTSEG_DIR)\n",
    "img, itk = xvertseg.load_xvertseg_img(infos.loc[0, 'image_mhd'])\n",
    "spacing = np.array(itk.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "target_spacing = (1., 1., 1.)\n",
    "resampled_img, resampled_spacing = resample_xvertseg_image(img, spacing, target_spacing=target_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('resampled_spacing:', resampled_spacing)\n",
    "print('resampled_img.shape:', resampled_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.animate_crop(resampled_img, step=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample Mask\n",
    "\n",
    "Masks have 6 classes embedded in their values.  To be resampled, they need to be split into binary masks, resized, re-binarized, and recombined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/juliandewit/kaggle_ndsb2017/blob/master/step1_preprocess_luna16.py\n",
    "\n",
    "XVERTSEG_MASK_VALS = (200, 210, 220, 230, 240)\n",
    "\n",
    "def xvertseg_mask_layers_gen(mask, vals=XVERTSEG_MASK_VALS):\n",
    "    '''\n",
    "    Avoid having every mask layer generated at the same time, to save on memory.\n",
    "    '''\n",
    "    for val in vals:\n",
    "        layer = np.zeros(mask.shape)\n",
    "        layer[mask == val] = 1.\n",
    "        yield layer, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimg, mitk = xvertseg.load_xvertseg_img(infos.loc[0, 'mask_mhd'])\n",
    "spacing = np.array(mitk.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "for layer, val in xvertseg_mask_layers_gen(mimg):\n",
    "    print('val:', val)\n",
    "    plt.hist(layer.ravel(), bins=256)\n",
    "    plt.show()\n",
    "    print('resampling...')\n",
    "    rlayer, rspacing = preprocessing.resample_image(layer, spacing, target_spacing)\n",
    "    print('resampled spacing:', rspacing)\n",
    "    plt.hist(rlayer.ravel(), bins=256)\n",
    "    plt.show()\n",
    "    lu, lcounts = np.unique(layer.ravel(), return_counts=True)\n",
    "    print('layer unique vals:', lu)\n",
    "    print('layer unique counts:', lcounts)\n",
    "    rlu, rlcounts = np.unique(rlayer.ravel(), return_counts=True)\n",
    "    print('rlayer unique vals:', rlu)\n",
    "    print('rlayer unique counts:', rlcounts)\n",
    "    \n",
    "    # display(util.animate_crop(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_mask(mask, p=0.5):\n",
    "    '''\n",
    "    mask: an array whose value will be thresholded by p.  >p -> 1.  <=p -> 0\n",
    "    '''\n",
    "    mask[mask > p] = 1\n",
    "    mask[mask <= p] = 0\n",
    "    return mask\n",
    "\n",
    "    \n",
    "def resample_xvetseg_mask_layer(layer, spacing, target_spacing, metadata_only=False, p=0.5):\n",
    "    '''\n",
    "    p: Binarization threshold.  Everything greater than this theshold is set to 1.  \n",
    "      Everything less than or equal to p is set to 0.\n",
    "    '''\n",
    "    print('resampling...')\n",
    "    resampled_layer, resampled_spacing = preprocessing.resample_image(\n",
    "        layer, spacing, target_spacing, metadata_only=metadata_only)\n",
    "    print('resampled spacing:', resampled_spacing)\n",
    "    \n",
    "    resampled_layer = binarize_mask(resampled_layer, p=p)\n",
    "    return resampled_layer, resampled_spacing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling makes the masks a little bit (0.0003% more of image is black) darker. \n",
    "for layer, val in xvertseg_mask_layers_gen(mimg):\n",
    "    print('layer.shape:', layer.shape)\n",
    "    print('layer val:', val)\n",
    "    num_voxels = np.product(layer.shape)\n",
    "    print('num_voxels:', num_voxels)\n",
    "    print('0.0%:', (1 - np.sum(layer) / num_voxels) * 100)\n",
    "    pct1 = np.sum(layer) / num_voxels * 100\n",
    "    print('1.0%:', pct1)\n",
    "    print('spacing:', spacing)\n",
    "    rlayer, rspacing = resample_xvetseg_mask_layer(layer, spacing, target_spacing)\n",
    "    print('rlayer.shape:', rlayer.shape)\n",
    "    rlu, rlcounts = np.unique(rlayer.ravel(), return_counts=True)\n",
    "    resampled_num_voxels = np.product(rlayer.shape)\n",
    "    print('resampled_num_voxels:', resampled_num_voxels)\n",
    "    print('0.0%:', (1 - np.sum(rlayer) / resampled_num_voxels) * 100)\n",
    "    rpct1 = (np.sum(rlayer) / resampled_num_voxels) * 100\n",
    "    print('1.0%:', rpct1)\n",
    "    # a gross measure of accuracy for the resampling and rebinarization process.\n",
    "    print('Number of 1.0/true voxels more (or less) than expected from the original 1.0%:')\n",
    "    print((rpct1 - pct1) * resampled_num_voxels)\n",
    "    print('rlayer unique vals:', rlu)\n",
    "    print('rlayer unique counts:', rlcounts)\n",
    "    display(util.animate_crop(rlayer, axis=0, step=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_xvertseg_mask(img, spacing, target_spacing, metadata_only=False, bin_thresh=0.5):\n",
    "    '''\n",
    "    vVertSeg image masks have 6 classes embedded in their values. \n",
    "    To be resampled, they need to be split into binary masks, resized, re-binarized, and recombined.\n",
    "    \n",
    "    image: a 3d volume that is an image mask. \n",
    "    spacing: the size of a voxel in some units.  E.g. [0.3, 0.3, 0.9]\n",
    "    target_spacing: the size of a voxel after resampling, in some units.  E.g. [1.0, 1.0, 1.0]\n",
    "    bin_thresh: binarization threshold.  Used to clean up mask after resampling.\n",
    "    \n",
    "    returns: resampled categorical and binary masks with target spacing adjusted because volumes have \n",
    "      integer dimensions.\n",
    "    '''\n",
    "    resampled_spacing = None\n",
    "    resampled_binary_mask = None\n",
    "    resampled_categorical_mask = None\n",
    "    # split the image into layers, one layer for each category (except background category).\n",
    "    for layer, val in xvertseg_mask_layers_gen(mimg):\n",
    "        print('resampling mask layer for val:', val)\n",
    "        # rlayer is a binary mask, resampled from layer.\n",
    "        rlayer, rspacing = resample_xvetseg_mask_layer(layer, spacing, target_spacing, p=bin_thresh)\n",
    "        \n",
    "        if resampled_spacing is None:\n",
    "            resampled_spacing = rspacing\n",
    "            print('resampled_spacing:', resampled_spacing)\n",
    "            resampled_binary_mask = np.zeros(rlayer.shape)\n",
    "            resampled_categorical_mask = np.zeros(rlayer.shape)\n",
    "            \n",
    "        if np.any(resampled_spacing != rspacing):\n",
    "            raise Exception('Resampled spacing did not match previous resampled spacing!', resampled_spacing, rspacing)\n",
    "            \n",
    "        # where rlayer and running mask both have data, ignore rlayer data (someone got there first).\n",
    "        rlayer[(resampled_binary_mask > 0) & (rlayer > 0)] = 0 \n",
    "        resampled_binary_mask = np.add(resampled_binary_mask, rlayer)\n",
    "        resampled_categorical_mask = np.add(resampled_categorical_mask, rlayer * val)\n",
    "        \n",
    "    resampled_binary_mask = binarize_mask(resampled_binary_mask, p=bin_thresh)\n",
    "    \n",
    "    return resampled_binary_mask, resampled_categorical_mask, resampled_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbmask, rcmask, rspacing = resample_xvertseg_mask(mimg, spacing, target_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.animate_crop(rbmask, axis=0, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.animate_crop(rcmask, axis=0, step=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Images and Masks\n",
    "\n",
    "This takes *forever*!\n",
    "\n",
    "Each xVertSeg scan has its image resampled, normalized and saved.  Any mask is resampled and saved as a categorical mask, like the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to preprocess xvertseg.\n",
    "# delete_existing: True to remove existing preprocessed images.\n",
    "# metadata_only: True to not generate any images and only read the original image.  Faster.  \n",
    "# bin_thresh: binary thresold for rebinarizing resampled binary masks.\n",
    "#   Only updates metadata, not images.\n",
    "# infos = xvertseg.preprocess_xvertseg(XVERTSEG_DIR, PP_XVERTSEG_DIR, PP_XVERTSEG_MD_PATH, start=0, metadata_only=False, \n",
    "#                    delete_existing=True, bin_thresh=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = xvertseg.read_xvertseg_metadata(PP_XVERTSEG_MD_PATH)\n",
    "infos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampled size for image006.\n",
    "r = 296, 296, 167\n",
    "# original size\n",
    "o = 1024, 1024, 100\n",
    "rv = np.product(r)\n",
    "ov = np.product(o)\n",
    "prop = rv/ov\n",
    "print('original shape:', o)\n",
    "print('resampled shape:', r)\n",
    "print('original volume:', ov)\n",
    "print('resampled volume:', rv)\n",
    "print('resampled proportion of orginal volume:', rv/ov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocessing.get_preprocessed_image(\n",
    "    '/data2/uvm_deep_learning_project/xVertSeg.v1/preprocessed/image015.npy')\n",
    "util.animate_crop(img, axis=0, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.animate_crop(preprocessing.get_preprocessed_image(\n",
    "    '/data2/uvm_deep_learning_project/xVertSeg.v1/preprocessed/mask015.npy'), axis=0, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = xvertseg.read_xvertseg_metadata(PP_XVERTSEG_MD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
