{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing xVertSeg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, Concatenate, Add)\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "importlib.reload(util)\n",
    "import preprocessing\n",
    "importlib.reload(preprocessing)\n",
    "import datagen\n",
    "importlib.reload(datagen)\n",
    "import modelutil\n",
    "importlib.reload(modelutil)\n",
    "\n",
    "SEED = 0\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1\n",
    "PATCH_SHAPE = (32, 32, 32)\n",
    "\n",
    "MODEL_NAME = 'model_09'\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "PP_XVERTSEG_IMG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_LOG_DIR = PROJECT_DATA_DIR / 'tensorboard' / MODEL_NAME\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_LOG_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_IMG_DIR, PP_XVERTSEG_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "\n",
    "def get_mhd_raw_id(d):\n",
    "    '''\n",
    "    d: a Path, a directory containing paired MetaImage format files.\n",
    "    returns a triple of a list of mhd files, of raw files, and of xvertseg scan ids.\n",
    "    '''\n",
    "        \n",
    "    mhds = [str(p) for p in list(d.glob('*.mhd'))]\n",
    "    ids = [int(re.search(r'.*?(\\d\\d\\d)\\.mhd$', p).group(1)) for p in mhds]\n",
    "    raws = [d / re.sub(r'\\.mhd$', '.raw', p) for p in mhds]\n",
    "    return mhds, raws, ids\n",
    "\n",
    "\n",
    "def get_xvertseg_infos(xvertseg_dir):\n",
    "    '''\n",
    "    Build a dataframe with columns: id, dataset, image_mhd, image_raw, mask_mhd, mask_raw, and labeled.\n",
    "    id is the number embedded in the xvertseg filenames.  xvertseg is split into 2 datasets, data1 and data2.\n",
    "    data1 is labeled, meaning it has segmentation masks.  data2 only has images.\n",
    "    \n",
    "    There are 15 labeled images and 10 unlabeled images.\n",
    "    \n",
    "    data_dir: the xVertSeg1.v1/Data1 dir, as a Path.\n",
    "    return: dataframe. \n",
    "    '''\n",
    "    # filename examples\n",
    "    # image016.mhd\n",
    "    # image016.raw\n",
    "    # mask001.mhd\n",
    "    # mask001.raw\n",
    "    \n",
    "    # Data1 has 15 images and masks (labeled data)\n",
    "    # Data2 has 10 test images with no mask.  Unlabeled data.\n",
    "    data1_dir = xvertseg_dir / 'Data1'\n",
    "    idir1 = data1_dir / 'images'\n",
    "    mdir1 = data1_dir / 'masks'\n",
    "    data2_dir = xvertseg_dir / 'Data2'\n",
    "    idir2 = data2_dir / 'images'\n",
    "    \n",
    "    img1_mhds, img1_raws, img1_ids = get_mhd_raw_id(idir1)\n",
    "    img1_df = pd.DataFrame({'id': img1_ids, 'image_mhd': img1_mhds, 'image_raw': img1_raws})\n",
    "    mask1_mhds, mask1_raws, mask1_ids = get_mhd_raw_id(mdir1)\n",
    "    mask1_df = pd.DataFrame({'id': mask1_ids, 'mask_mhd': mask1_mhds, 'mask_raw': mask1_raws})\n",
    "    img2_mhds, img2_raws, img2_ids = get_mhd_raw_id(idir2)\n",
    "    img2_df = pd.DataFrame({'id': img2_ids, 'image_mhd': img2_mhds, 'image_raw': img2_raws})\n",
    "    img2_df['dataset'] = ['data2'] * len(img2_df)\n",
    "    \n",
    "    df = img1_df.merge(mask1_df, on='id')\n",
    "    df['dataset'] = ['data1'] * len(df)\n",
    "    df = pd.concat([df, img2_df]).sort_values('id').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_xvertseg_infos(XVERTSEG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xvertseg_img(path):\n",
    "    # https://github.com/juliandewit/kaggle_ndsb2017/blob/master/step1_preprocess_luna16.py\n",
    "    itk = SimpleITK.ReadImage(path)\n",
    "    img = SimpleITK.GetArrayFromImage(itk)\n",
    "    return img, itk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at an image and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, itk = load_xvertseg_img(df.loc[0, 'image_mhd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.animate_crop(img, crop=(0.0, 1, 0.5, 0.8, 0.3, 0.6), step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, mitk = load_xvertseg_img(df.loc[0, 'mask_mhd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.animate_crop(mask, crop=(0.0, 1, 0.5, 0.8, 0.3, 0.6), step=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at mask\n",
    "\n",
    "The mask has 6 unique values: 0, 200, 210, 220, 230, 240.  These correspond to background and the vertebrae l1, l2, ..., l5, I think.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mask.ravel())\n",
    "plt.show()\n",
    "# looks like a typical ct scan in hounsfield units...or does it?  No -1000 values?  Looks like the units are hounsfield + 1000.\n",
    "plt.hist(img.ravel(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample/Resize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/juliandewit/kaggle_ndsb2017/blob/master/step1_preprocess_luna16.py\n",
    "\n",
    "\n",
    "def normalize_xvertseg_image(img):\n",
    "    '''\n",
    "    img: an xvertseg xyz oriented image.\n",
    "    \n",
    "    Before normalization, \n",
    "    Normalize voxel units by clipping them to lie between -1000 and 1000 hounsfield units \n",
    "    and then scale number to between 0 and 1.\n",
    "    '''\n",
    "    MIN_BOUND = 0000.0 # Air: -1000, Water: 0 hounsfield units.\n",
    "    MAX_BOUND = 2000.0 # Bone: 200, 700, 3000.  https://en.wikipedia.org/wiki/Hounsfield_scale\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image > 1] = 1.\n",
    "    image[image < 0] = 0.\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_image_historgrams():\n",
    "    infos = get_xvertseg_infos(XVERTSEG_DIR)\n",
    "    for i in range(len(infos)):\n",
    "        img_zyx, itk = load_xvertseg_img(infos.loc[i, 'image_mhd'])\n",
    "        img = np.swapaxes(img_zyx, 0, 2) # swap z and x.\n",
    "        plt.hist(img.ravel(), 256)\n",
    "        plt.title('image histogram for id ' + str(infos.loc[i, 'id']))\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "def get_preprocessed_xvertseg_image_path(id, preprocessed_dir):\n",
    "    return str(Path(preprocessed_dir, f'image{id:03}.npy'))\n",
    "\n",
    "\n",
    "def get_preprocessed_xvertseg_mask_path(id, preprocessed_dir):\n",
    "    return str(Path(preprocessed_dir, f'mask{id:03}.npy'))\n",
    "\n",
    "\n",
    "def resample_xvertseg_test(data_dir, out_dir, metadata_only=False):\n",
    "    infos = get_xvertseg_infos(data_dir)\n",
    "    for i in range(1): # range(len(infos)):\n",
    "        \n",
    "        img_zyx, itk = load_xvertseg_img(infos.loc[i, 'image_mhd'])\n",
    "        img = np.swapaxes(img_zyx, 0, 2) # swap z and x.\n",
    "\n",
    "        origin = np.array(itk.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "        spacing = np.array(itk.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "        direction = np.array(itk.GetDirection())  \n",
    "        print('img shape:', img.shape)\n",
    "        print('img origin:', origin)\n",
    "        print('img spacing:', spacing)\n",
    "        print('img direction:', direction)\n",
    "\n",
    "        # resample image\n",
    "        target_spacing = (1.0, 1.0, 1.0)\n",
    "        print('image spacing:', spacing)\n",
    "        print('new spacing:', target_spacing)\n",
    "        resampled_img, resampled_spacing = resample_image(img, spacing, target_spacing, metadata_only=metadata_only)\n",
    "        print('resampled image spacing:', resampled_spacing)\n",
    "        print('resampled image shape:', resampled_img.shape)\n",
    "        infos.loc[i, 'pp_image_pixdim0'] = resampled_spacing[0]\n",
    "        infos.loc[i, 'pp_image_pixdim1'] = resampled_spacing[1]\n",
    "        infos.loc[i, 'pp_image_pixdim2'] = resampled_spacing[2]\n",
    "        infos.loc[i, 'pp_image_dim0'] = resampled_img.shape[0]\n",
    "        infos.loc[i, 'pp_image_dim1'] = resampled_img.shape[1]\n",
    "        infos.loc[i, 'pp_image_dim2'] = resampled_img.shape[2]\n",
    "\n",
    "        # Normalize voxel intensities\n",
    "        if not metadata_only:\n",
    "            normalized_img = normalize_xvertseg_image(resampled_img)\n",
    "            print('Normalized image shape:', normalized_img.shape)\n",
    "        \n",
    "        # save processed image\n",
    "        path = get_preprocessed_image_path(scan_id, dest_dir)\n",
    "        print(f'Saving preprocessed image to {path}.')\n",
    "        if not metadata_only:\n",
    "            np.save(path, normalized_img)\n",
    "\n",
    "        # resample mask\n",
    "        if infos.loc[i, 'image_mhd'].notna():\n",
    "            mimg_zyx, mitk = load_xvertseg_img(infos.loc[0, 'mask_mhd'])\n",
    "            mimg = np.swapaxes(mimg_zyx, 0, 2)\n",
    "            mask_spacing = np.array(mitk.GetSpacing()) # xyz spacing\n",
    "            print('unique mask values:', np.unique(mimg.ravel()))\n",
    "            resampled_mask, resampled_spacing = resample_image(mimg, mask_spacing, target_spacing,\n",
    "                                                               metadata_only=metadata_only)\n",
    "            print('resampled image spacing:', resampled_spacing)\n",
    "            print('resampled image shape:', resampled_mask.shape)\n",
    "            infos.loc[i, 'pp_mask_pixdim0'] = resampled_spacing[0]\n",
    "            infos.loc[i, 'pp_mask_pixdim1'] = resampled_spacing[1]\n",
    "            infos.loc[i, 'pp_mask_pixdim2'] = resampled_spacing[2]\n",
    "            infos.loc[i, 'pp_mask_dim0'] = resampled_mask.shape[0]\n",
    "            infos.loc[i, 'pp_mask_dim1'] = resampled_mask.shape[1]\n",
    "            infos.loc[i, 'pp_mask_dim2'] = resampled_mask.shape[2]\n",
    "        \n",
    "        \n",
    "def resample_xvertseg_image_test(data_dir, dest_dir, num=None, metadata_only=False):\n",
    "    '''\n",
    "    data_dir: Path to an xVertSeg.v1 dir.\n",
    "    out_dir: where to save preprocessed images and masks.\n",
    "    '''\n",
    "    infos = get_xvertseg_infos(data_dir)\n",
    "    if num is None:\n",
    "        num = len(infos)\n",
    "        \n",
    "    for i in range(num):\n",
    "        print('i:', i)\n",
    "        \n",
    "        img_zyx, itk = load_xvertseg_img(infos.loc[i, 'image_mhd'])\n",
    "        img = np.swapaxes(img_zyx, 0, 2) # swap z and x.\n",
    "\n",
    "        origin = np.array(itk.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "        spacing = np.array(itk.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "        direction = np.array(itk.GetDirection())  \n",
    "        print('img shape:', img.shape)\n",
    "        print('img origin:', origin)\n",
    "        print('img spacing:', spacing)\n",
    "        print('img direction:', direction)\n",
    "\n",
    "        # resample image\n",
    "        target_spacing = (1.0, 1.0, 1.0)\n",
    "        print('image spacing:', spacing)\n",
    "        print('new spacing:', target_spacing)\n",
    "        resampled_img, resampled_spacing = preprocessing.resample_image(img, spacing, target_spacing, metadata_only=metadata_only)\n",
    "        print('resampled image spacing:', resampled_spacing)\n",
    "        print('resampled image shape:', resampled_img.shape)\n",
    "        infos.loc[i, 'pp_image_pixdim0'] = resampled_spacing[0]\n",
    "        infos.loc[i, 'pp_image_pixdim1'] = resampled_spacing[1]\n",
    "        infos.loc[i, 'pp_image_pixdim2'] = resampled_spacing[2]\n",
    "        infos.loc[i, 'pp_image_dim0'] = resampled_img.shape[0]\n",
    "        infos.loc[i, 'pp_image_dim1'] = resampled_img.shape[1]\n",
    "        infos.loc[i, 'pp_image_dim2'] = resampled_img.shape[2]\n",
    "\n",
    "        # Normalize voxel intensities\n",
    "        if not metadata_only:\n",
    "            normalized_img = normalize_xvertseg_image(resampled_img)\n",
    "            print('Normalized image shape:', normalized_img.shape)\n",
    "        \n",
    "        # save processed image\n",
    "        print(infos.head())\n",
    "        path = get_preprocessed_xvertseg_image_path(infos.loc[i, 'id'], dest_dir)\n",
    "        print(f'Saving preprocessed image to {path}.')\n",
    "        if not metadata_only:\n",
    "            np.save(path, normalized_img)\n",
    "\n",
    "        return infos\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = resample_xvertseg_image_test(XVERTSEG_DIR, PP_XVERTSEG_IMG_DIR, num=2, metadata_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = get_xvertseg_infos(XVERTSEG_DIR)\n",
    "plt.hist(img.ravel())\n",
    "plt.title('infos' + str(infos.loc[0, 'id']))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine original spacing and resampled spacing of mask using different spline orders to see if that will help\n",
    "# the blurring that causes when resizing the mask.\n",
    "spacing = np.array(mitk.GetSpacing())\n",
    "target_spacing = (1.0, 1.0, 1.0)\n",
    "nmask, nspacing = preprocessing.resample_mask(mask, spacing, target_spacing, order=3)\n",
    "nmask5, nspacing5 = preprocessing.resample_mask(mask, spacing, target_spacing, order=5)\n",
    "nmask0, nspacing0 = preprocessing.resample_mask(mask, spacing, target_spacing, order=0)\n",
    "print(spacing, '->', target_spacing, '->', nspacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask.shape)\n",
    "print(nmask.shape)\n",
    "display(util.animate_crop(nmask, step=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nmask5.shape)\n",
    "display(util.animate_crop(nmask5, step=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nmask0.shape)\n",
    "display(util.animate_crop(nmask0, step=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rav = nmask.ravel()\n",
    "prav = rav[rav > 0]\n",
    "\n",
    "plt.hist(rav, bins=256) # looks the same\n",
    "plt.show()\n",
    "plt.hist(prav, bins=256) # only > 0.  spikes at 200, 210, 220, 230, 240.  Also a smaller spike at 255.\n",
    "plt.show()\n",
    "print(pd.unique(rav)) # except every number from 0 to 256 is present\n",
    "plt.hist(pd.unique(rav), bins=256) # every number is present.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rav0 = nmask0.ravel()\n",
    "prav0 = rav0[rav0 > 0]\n",
    "rav5 = nmask5.ravel()\n",
    "prav5 = rav5[rav5 > 0]\n",
    "plt.hist(rav0, bins=256) # looks the same\n",
    "plt.show()\n",
    "plt.hist(prav0, bins=256) # only > 0.  spikes at 200, 210, 220, 230, 240.  Also a smaller spike at 255.\n",
    "plt.show()\n",
    "plt.hist(rav5, bins=256) # looks the same\n",
    "plt.show()\n",
    "plt.hist(prav5, bins=256) # only > 0.  spikes at 200, 210, 220, 230, 240.  Also a smaller spike at 255.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_historgrams()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess xVertSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_residual_encoder_decoder_block(x, n_a, n_d=1, use_bn=True):\n",
    "\n",
    "    x = batchnorm_conv_block(x, n_a, use_bn=use_bn)\n",
    "    \n",
    "    if n_d > 0:\n",
    "        x_e = x # shape: (32, 32, 32, 16)\n",
    "        x_e = MaxPooling3D(padding='same')(x_e) # shape: (16, 16, 16, 16)\n",
    "        x_e = build_residual_encoder_decoder_block(x_e, n_a, n_d - 1, use_bn=use_bn) # recursive call\n",
    "        x_d = UpSampling3D()(x_e) # shape (32, 32, 32, 16)\n",
    "        x = Concatenate()([x, x_d]) # residual join.  shape (32, 32, 32, 32)\n",
    "        x = batchnorm_conv_block(x, n_a, use_bn=use_bn)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def batchnorm_conv_block(x, n_a, use_bn=True):\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x) # shape: (32, 32, 32, 1) = 32768\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_residual_block(x, n_a, n_l=1, use_bn=True):\n",
    "    '''\n",
    "    n_l: number of layers/convolutions in the residual path.\n",
    "    '''\n",
    "    x_r = x\n",
    "    for i in range(n_l):\n",
    "        x_r = batchnorm_conv_block(x_r, n_a, use_bn=use_bn)\n",
    "        \n",
    "    x = Add()([x, x_r])  \n",
    "    return x\n",
    "\n",
    "\n",
    "def build_downsampling_conv_block(x, n_a, use_bn=True):\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same', activation='relu')(x) \n",
    "    return x\n",
    "    \n",
    "    \n",
    "def build_model(input_shape, n_a=16, n_r=2, n_d=4, use_bn=True):\n",
    "    '''\n",
    "    3D convolutional autoencoder that treats u-net architecture as a residual block.\n",
    "    \n",
    "    1 poolings reduce input from shape to shape/2, which in 3d is 1/8th the size of the original shape,\n",
    "    a very respectable compression factor.\n",
    "    '''\n",
    "\n",
    "    x_input = Input(shape=input_shape)\n",
    "    x = x_input\n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*2, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*2, n_l=1, use_bn=use_bn) \n",
    "\n",
    "    # u-net\n",
    "#    x = build_residual_encoder_decoder_block(x, n_a=(n_a//2), n_d=n_d)\n",
    "    \n",
    "    # upsample for autoencoder\n",
    "#     x_ae = UpSampling3D()(x)\n",
    "#     x_ae = batchnorm_conv_block(x_ae, n_a=n_a)\n",
    "#     y_ae = Conv3D(1, kernel_size=(3, 3, 3), padding='same', activation='sigmoid')(x)\n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*4, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*4, n_l=1, use_bn=use_bn) \n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*8, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*8, n_l=1, use_bn=use_bn) \n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*16, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*16, n_l=1, use_bn=use_bn) \n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*32, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*32, n_l=1, use_bn=use_bn) \n",
    "    x = build_residual_block(x, n_a=n_a*32, n_l=1, use_bn=use_bn)\n",
    "     \n",
    "    # pool and predict\n",
    "    x = GlobalMaxPooling3D()(x)\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Dense(n_a*16, activation='relu')(x)\n",
    "    y_frac = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=y_frac)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=(None, None, None, 1,), n_a=4, n_r=4, n_d=4, use_bn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model\n",
    "\n",
    "- Add callbacks to save model every 20 epochs and to log performance stats every epoch, so we have the results saved somewhere for charting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history, log_path = modelutil.train_model(\n",
    "#     model, train_gen, val_gen, epochs=40, batch_size=BATCH_SIZE, models_dir=MODELS_DIR, model_name=MODEL_NAME, \n",
    "#     log_dir=LOG_DIR, tensorboard_log_dir=TENSORBOARD_LOG_DIR, max_queue_size=20, use_multiprocessing=True, \n",
    "#     class_weight={0: 1, 1: 5})\n",
    "history, log_path = modelutil.train_model_epoch(train_gen, val_gen, epoch=40, epochs=200, batch_size=BATCH_SIZE, models_dir=MODELS_DIR, model_name=MODEL_NAME, \n",
    "    log_dir=LOG_DIR, tensorboard_log_dir=TENSORBOARD_LOG_DIR, max_queue_size=20, use_multiprocessing=True, \n",
    "    class_weight={0: 1, 1: 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metrics from the log file\n",
    "# log_path = LOG_DIR / (model_name + '_2018-04-26T17:29:02.902740_log.csv')\n",
    "log_path = Path('/data2/uvm_deep_learning_project/log/model_09_2018-04-28T02:02:18.169239_log.csv')\n",
    "metrics = pd.read_csv(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([metrics[::10], metrics[-1:]])) # every 10th metric and the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy \n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,1.0]) # Show results on 0..1 range\n",
    "plt.plot(metrics[\"acc\"])\n",
    "plt.plot(metrics[\"val_acc\"])\n",
    "plt.legend(['Training Accuracy', \"Validation Accuracy\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.plot(metrics[\"loss\"])\n",
    "plt.plot(metrics[\"val_loss\"])\n",
    "plt.legend(['Training Loss', \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Results Over Time\n",
    "\n",
    "Visualize how the results of the model improve over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix_by_epochs()\n",
    "modelutil.confusion_matrix_by_epochs(MODELS_DIR, MODEL_NAME, [1, 10, 200], val_gen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
