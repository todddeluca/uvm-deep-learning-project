{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 03\n",
    "\n",
    "Try a really shallow autoencoder, one compression to 1/8 original input volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, Conv3D, \n",
    "                          UpSampling3D, BatchNormalization)\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "importlib.reload(util)\n",
    "import preprocessing\n",
    "importlib.reload(preprocessing)\n",
    "import datagen\n",
    "importlib.reload(datagen)\n",
    "\n",
    "SEED = 0\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SHAPE = (32, 32, 32)\n",
    "\n",
    "MODEL_NAME = 'model_03'\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_LOG_DIR = PROJECT_DATA_DIR / 'tensorboard' / MODEL_NAME\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_LOG_DIR, TMP_DIR, PP_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, val_gen = datagen.get_nifti_datagens(preprocessed_metadata_path=PP_MD_PATH,\n",
    "                                                batch_size=BATCH_SIZE, crop_shape=PATCH_SHAPE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    '''\n",
    "    Very simple 3D convolutional autoencoder.\n",
    "    1 poolings reduce input from shape to shape/2, which in 3d is 1/8th the size of the original shape,\n",
    "    a very respectable compression factor.\n",
    "    '''\n",
    "    n_a = 32\n",
    "\n",
    "    x_input = Input(shape=input_shape) # shape:  (32, 32, 32, 1) == 32768\n",
    "    x = x_input\n",
    "\n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x) # shape: (32, 32, 32, 32) = 1048576\n",
    "    x = AveragePooling3D(padding='same')(x) # shape: (16, 16, 16, 32) = 131072\n",
    "\n",
    "    x = Conv3D(n_a * 2, kernel_size=(3, 3, 3), padding='same', activation='relu')(x) # shape: (16, 16, 16, 64) = 262144\n",
    "    x = UpSampling3D()(x) # shape (32, 32, 32, 64) = 2097152\n",
    "\n",
    "    y = Conv3D(1, kernel_size=(3, 3, 3), padding='same', activation='sigmoid')(x) # shape: (32, 32, 32, 1) = 32768\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=y)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "model = build_model(PATCH_SHAPE + (1,))\n",
    "print(model.summary())\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model\n",
    "\n",
    "- Add callbacks to save model every 20 epochs and to log performance stats every epoch, so we have the results saved somewhere for charting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(models_dir, model_name, epoch):\n",
    "    '''\n",
    "    Paths match the template that the keras checkpoint callback uses to save models.\n",
    "    '''\n",
    "    model_path = models_dir  /  (model_name + f'_{epoch:02d}.h5')\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def train_model_epoch(train_gen, val_gen, epoch, epochs=EPOCHS, batch_size=BATCH_SIZE, models_dir=MODELS_DIR, \n",
    "                model_name=MODEL_NAME, log_dir=LOG_DIR,\n",
    "                tensorboard_log_dir=TENSORBOARD_LOG_DIR, max_queue_size=10):\n",
    "    \n",
    "    path = get_model_path(models_dir, model_name, epoch)\n",
    "    model = keras.models.load_model(path)\n",
    "    return train_model(model=model, train_gen=train_gen, val_gen=val_gen, epochs=epochs, \n",
    "                       initial_epoch=epoch, batch_size=batch_size, models_dir=models_dir, \n",
    "                       model_name=model_name, log_dir=log_dir, tensorboard_log_dir=tensorboard_log_dir,\n",
    "                       max_queue_size=10)\n",
    "\n",
    "\n",
    "def train_model(model, train_gen, val_gen, epochs=EPOCHS, initial_epoch=0, batch_size=BATCH_SIZE, models_dir=MODELS_DIR, \n",
    "                model_name=MODEL_NAME, log_dir=LOG_DIR,\n",
    "                tensorboard_log_dir=TENSORBOARD_LOG_DIR, max_queue_size=10):\n",
    "    # Saving model\n",
    "    model_path = models_dir  /  (model_name +'_{epoch:02d}.h5')\n",
    "    print('model path:', model_path)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        str(model_path), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, \n",
    "        mode='auto', period=1)\n",
    "    \n",
    "    # Stop when validation loss stops improving\n",
    "    early_cb = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "    \n",
    "    # Save logs for each run to logfile\n",
    "    log_path = log_dir / (model_name + '_' + datetime.datetime.now().isoformat() + '_log.csv')\n",
    "    print('log path:', log_path)\n",
    "    log_cb = keras.callbacks.CSVLogger(str(log_path), separator=',', append=False)\n",
    "    \n",
    "    # Enable Tensorboard\n",
    "    print('tensorboard log dir:', tensorboard_log_dir)\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=str(tensorboard_log_dir), \n",
    "                                                 histogram_freq=0, write_graph=True, write_images=True)\n",
    "    \n",
    "    # Fit Model\n",
    "    history = model.fit_generator(train_gen, epochs=epochs, initial_epoch=initial_epoch, validation_data=val_gen, \n",
    "                        callbacks=[checkpoint_cb, log_cb, tensorboard_cb], max_queue_size=max_queue_size)\n",
    "    return history, log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, log_path = train_model(model, train_gen, val_gen, epochs=40)\n",
    "# history, log_path = train_model_epoch(train_gen, val_gen, epoch=100, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metrics from the log file\n",
    "# log_path = LOG_DIR / (model_name + '_2018-04-26T17:29:02.902740_log.csv')\n",
    "log_path = sorted(LOG_DIR.glob(f'{MODEL_NAME}*_log.csv'), reverse=True)[0]\n",
    "print('most recent log_path:', log_path)\n",
    "\n",
    "metrics = pd.read_csv(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([metrics[::10], metrics[-1:]])) # every 10th metric and the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy \n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,1.0]) # Show results on 0..1 range\n",
    "plt.plot(metrics[\"acc\"])\n",
    "plt.plot(metrics[\"val_acc\"])\n",
    "plt.legend(['Training Accuracy', \"Validation Accuracy\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.plot(metrics[\"loss\"])\n",
    "plt.plot(metrics[\"val_loss\"])\n",
    "plt.legend(['Training Loss', \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Effect of Autoencoder Training\n",
    "\n",
    "Use models from different training epochs to encode images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_by_epochs(models_dir, model_name, epochs, train_gen, val_gen):\n",
    "    kind_gens = (('train', train_gen), ('val', val_gen))\n",
    "    kind_batches = [(kind, gen[0]) for kind, gen in kind_gens]\n",
    "    for epoch in epochs:\n",
    "            print('Epoch {}:'.format(epoch))\n",
    "            path = get_model_path(models_dir, model_name, epoch)\n",
    "            model = keras.models.load_model(path)\n",
    "            for kind, (batch_x, batch_y) in kind_batches:\n",
    "                print(f'{kind} data set')\n",
    "                batch_pred = model.predict_on_batch(batch_x)\n",
    "                for i in range(len(batch_x)):\n",
    "                    print(f'predicted vs truth for image {i}')\n",
    "                    display(util.animate_crop(np.squeeze(batch_pred[i])))\n",
    "                    display(util.animate_crop(np.squeeze(batch_y[i])))\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_by_epochs(MODELS_DIR, MODEL_NAME, [1, 10, 40], train_gen, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
