{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 24 Gated Segmentation Net\n",
    "\n",
    "Try a gated segmentation net and see if it does better.\n",
    "\n",
    "GPU: Tesla K80 11GB.\n",
    "\n",
    "### Results\n",
    "\n",
    "\n",
    "\n",
    "### To Try\n",
    "\n",
    "- Loss Function\n",
    "    - Try filtering out empty crops from training, so dice or jaccard coefficients are valid.\n",
    "    - Try removing smoothing from numerator of loss function, so there is no way to improve the network on empty patches.\n",
    "- u-net or v-net\n",
    "- spatial pyramid pooling\n",
    "- Use small patches, small batches, batchnorm\n",
    "- making sure my loss functions work.\n",
    "- mean squared error loss\n",
    "- Add dilated convolution stack to end of network (small fov increase).\n",
    "- Using Dropout (try 0.1)\n",
    "- A shallow u-net: Pooling once and taking advantage of the smaller volume to increase channels and layers.  This would lead to a greatly increased fov.  \n",
    "- experiment with downsampling: try stride 2 2x2x2 conv like in v-net, not that they offered much justification for why this was better than the usual stride 2 3x3x3 conv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, \n",
    "                          Concatenate, Add, Multiply,\n",
    "                          GaussianNoise, Dropout, Conv3DTranspose, \n",
    "                         )\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK # xvertseg MetaImage files\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "import preprocessing\n",
    "import datagen\n",
    "import modelutil\n",
    "import xvertseg\n",
    "import augmentation\n",
    "import metrics\n",
    "\n",
    "MODEL_NAME = 'model_24'\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "# DATA_DIR = Path('~/data/2018').expanduser()\n",
    "# UVMMC\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "# xVertSeg\n",
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "PP_XVERTSEG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_MD_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_DIR = PROJECT_DATA_DIR / 'tensorboard'\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_DIR, PP_XVERTSEG_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# I love u autoreload!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 25 # random seed for dataset shuffling and splitting.\n",
    "VALIDATION_SPLIT = 0.2 # 3 samples for validation\n",
    "TEST_SPLIT = 0.134 # 2 samples for test\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "N_BATCHES = 10 # The number of batches per epoch or None\n",
    "NUM_SAMPLES = 1 # Show each image num_samples times per epoch. Ignored if N_BATCHES is set.\n",
    "MAX_QUEUE_SIZE = 20\n",
    "EPOCHS = 30\n",
    "\n",
    "# PATCH_SHAPE = (32, 32, 32)\n",
    "# PATCH_SHAPE = (64, 64, 64) # Used to crop images for training (data augmentation, memory, speed)\n",
    "PATCH_SHAPE = (128, 128, 128) # Big.  Good for visualization.\n",
    "# PATCH_SHAPE = None # Full sized images\n",
    "\n",
    "# INPUT_SHAPE = (PATCH_SHAPE + (1,)) # Model input shape adds channel dimension, but not examples dim.\n",
    "INPUT_SHAPE = (None, None, None, 1) # Accept variable size volumes/images.\n",
    "\n",
    "BINARY_MASK_THRESH = 0.5 # > threshold = 1. <= thresh = 0.\n",
    "\n",
    "TRANSPOSE = False\n",
    "FLIP = 0.5\n",
    "GRAY_STD = 0.01\n",
    "\n",
    "# Visualize model using the first set of hyperparams\n",
    "# KERNEL_SIZE = (7, 7, 7)\n",
    "# KERNEL_SIZE = (5, 5, 5)\n",
    "KERNEL_SIZE = (3, 3, 3)\n",
    "N_A = 8 # number of channels\n",
    "N_R = 32 # number of residual blocks\n",
    "DROPOUT = None # 0.1\n",
    "NOISE = None # 0.0001\n",
    "\n",
    "W0 = 1 # binary cross entropy weight for class 0\n",
    "W1 = 100 # weight informed by the 1-to-0 ratio in the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_func = lambda: xvertseg.read_xvertseg_metadata(PP_XVERTSEG_MD_PATH)\n",
    "train_gen, val_gen, test_gen = xvertseg.get_xvertseg_datagens(\n",
    "    infos_func, seed=SEED, validation_split=VALIDATION_SPLIT, test_split=TEST_SPLIT)\n",
    "\n",
    "train_gen.config(batch_size=BATCH_SIZE, length=N_BATCHES, crop_shape=PATCH_SHAPE, flip=FLIP, \n",
    "                 transpose=TRANSPOSE, gray_std=GRAY_STD, num_samples=NUM_SAMPLES).reindex()\n",
    "val_gen.config(batch_size=BATCH_SIZE, crop_shape=PATCH_SHAPE, flip=FLIP, \n",
    "               transpose=TRANSPOSE, gray_std=GRAY_STD).reindex()\n",
    "# val_gen.config(batch_size=1).reindex() # Test full image\n",
    "test_gen.config(batch_size=1).reindex() # Evaluate using full image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, n_a, kernel_size=(3,3,3), activation='relu'):\n",
    "        x_initial = x\n",
    "        x = Conv3D(n_a, kernel_size=kernel_size, padding='same', activation=activation)(x)\n",
    "        x = Add()([x_initial, x])  \n",
    "        return x\n",
    "    \n",
    "    \n",
    "def build_model(input_shape, n_a=4, n_r=4, noise=None, loss='binary_crossentropy', metrics=[],\n",
    "                kernel_size=3):\n",
    "    '''\n",
    "    Input conv 2 times.  16 channels. 33V = 1 + (16 * 2)  Fov: 5\n",
    "downconv residual conv 2 times.  64 channels.  32V = V/8 * (64 * 2 * 2).  Fov: 5 + 8\n",
    "Downconv residual conv 32 times. 128 channels.  Fov 269 = 13 + 256.  128V = V/64 * (128 * 32 * 2)\n",
    "Upconv concat residual conv 2 times.  64 channels.  Fov = 285 = 269 + 16.  56V = V/8 * (64 + 128 + (64 * 2 * 2))\n",
    "Upconv concat conv conv conv 16 channels.  Fov 289 = 285 + 4.  67V = 16 + 32 + 16 * 2 + 1\n",
    "\n",
    "    returns: Keras model\n",
    "    '''\n",
    "\n",
    "    x_input = Input(shape=input_shape)\n",
    "    x = x_input\n",
    "    \n",
    "    # noise regularization\n",
    "    if noise: \n",
    "        x = GaussianNoise(stddev=noise)(x)\n",
    "\n",
    "    x = Conv3D(n_a, kernel_size=kernel_size, padding='same', activation='relu')(x)\n",
    "    x = Conv3D(n_a, kernel_size=kernel_size, padding='same', activation='relu')(x)\n",
    "    \n",
    "    # downsample\n",
    "    x_init = x # save x for the gated merge\n",
    "    x = Conv3D(n_a*2, kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "    x = residual_block(x, n_a*2, kernel_size=kernel_size)    \n",
    "    x = residual_block(x, n_a*2, kernel_size=kernel_size)    \n",
    "\n",
    "    # downsample\n",
    "    x = Conv3D(n_a*4, kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "    x = residual_block(x, n_a*4, kernel_size=kernel_size)    \n",
    "    x = residual_block(x, n_a*4, kernel_size=kernel_size)    \n",
    "\n",
    "    # downsample\n",
    "    x = Conv3D(n_a*4, kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "    x = residual_block(x, n_a*4, kernel_size=kernel_size)    \n",
    "    x = residual_block(x, n_a*4, kernel_size=kernel_size)    \n",
    "\n",
    "    # downsample\n",
    "    x = Conv3D(n_a*4, kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "    x = residual_block(x, n_a*4, kernel_size=kernel_size)    \n",
    "    x = residual_block(x, n_a*4, kernel_size=kernel_size)    \n",
    "\n",
    "    # downsample\n",
    "    x = Conv3D(n_a*4, kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "    x = residual_block(x, n_a*4, kernel_size=kernel_size)    \n",
    "    x = residual_block(x, n_a*4, kernel_size=kernel_size)    \n",
    "\n",
    "    # upsample coarsely and gate\n",
    "    x = Conv3D(n_a, kernel_size=(1, 1, 1), activation='sigmoid')(x)\n",
    "    x = UpSampling3D(size=(32, 32, 32))(x)\n",
    "    x = Multiply()([x, x_init])\n",
    "    \n",
    "    # downsample\n",
    "    x0 = x\n",
    "    x = Conv3D(n_a*2, kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "    x = residual_block(x, n_a*2, kernel_size=kernel_size)    \n",
    "    x = residual_block(x, n_a*2, kernel_size=kernel_size)    \n",
    "\n",
    "    # downsample\n",
    "    x1 = x\n",
    "    x = Conv3D(n_a*4, kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "    for j in range(n_r):\n",
    "        x = residual_block(x, n_a*4, kernel_size=kernel_size)    \n",
    "    \n",
    "    # upsample\n",
    "    x = Conv3DTranspose(n_a*2, kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "    x = Concatenate()([x, x1])\n",
    "    x = Conv3D(n_a*2, kernel_size=kernel_size, padding='same', activation='relu')(x)\n",
    "    x = residual_block(x, n_a*2, kernel_size=kernel_size)\n",
    "    \n",
    "    # upsample\n",
    "    x = Conv3DTranspose(n_a, kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "    x = Concatenate()([x, x0])\n",
    "    x = Conv3D(n_a, kernel_size=kernel_size, padding='same', activation='relu')(x)\n",
    "    x = Conv3D(n_a, kernel_size=kernel_size, padding='same', activation='relu')(x)\n",
    "    \n",
    "    # output\n",
    "    y = Conv3D(1, kernel_size=(1, 1, 1), activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=y)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'] + metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "# weighted_binary_crossentropy_loss = metrics.weighted_binary_crossentropy_loss_func(w0=W0, w1=W1)\n",
    "# dice_coefficient_loss = metrics.make_dice_coefficient_loss(smooth_numerator=True, smooth=1e-5)\n",
    "\n",
    "model = build_model(input_shape=INPUT_SHAPE, n_a=N_A, n_r=N_R,\n",
    "                    noise=NOISE, \n",
    "#                     loss=dice_coefficient_loss,\n",
    "#                     loss='binary_crossentropy',\n",
    "#                     loss=metrics.dice_coefficient_loss,\n",
    "                    loss=metrics.dice_coefficient2_loss,\n",
    "#                     loss=weighted_binary_crossentropy_loss,\n",
    "                    metrics=[metrics.dice_coefficient, metrics.binary_dice_coefficient],\n",
    "                    kernel_size=KERNEL_SIZE)\n",
    "print(model.summary())\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [modelutil.get_tensorboard_callback(TENSORBOARD_DIR, MODEL_NAME),\n",
    "             modelutil.get_logger_callback(LOG_DIR, MODEL_NAME),\n",
    "             modelutil.get_checkpoint_callback(MODELS_DIR, MODEL_NAME),\n",
    "            ]\n",
    "# datagen shuffles every epoch\n",
    "history = model.fit_generator(train_gen, epochs=EPOCHS, validation_data=val_gen, \n",
    "                              callbacks=callbacks, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                              use_multiprocessing=False, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Notes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "course gated net + shallow u-net. \n",
    "n_a = 16, n_r = 32, n_a for d2 is n_a*4, not n_a*8\n",
    "loss: metrics.make_dice_coefficient_loss(smooth_numerator=True, smooth=1e-5) # sorensen\n",
    "d0: 16 channels.  d1: 32 channels.  d2: 64 channels.  32 residual conv in d2.  No noise or dropout or batchnorm.  batch size 1. \n",
    "Total params: 5,188,737\n",
    "Total volume: \n",
    "Final FOV ~289\n",
    "53s/epoch\n",
    "\n",
    "Not much different from smooth_numerator=False in terms of loss.  Bouncing around 0.3\n",
    "\n",
    "---\n",
    "\n",
    "n_a = 8\n",
    "loss: metrics.dice_coefficient2_loss # same as pyramid pooling model 19\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metrics from the log file\n",
    "# get latest log path\n",
    "log_path = sorted(LOG_DIR.glob(f'{MODEL_NAME}*_log.csv'))[-1]\n",
    "print(log_path)\n",
    "log_data = pd.read_csv(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([log_data[::10], log_data[-1:]]) # every 10th metric and the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy \n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,1.0]) # Show results on 0..1 range\n",
    "plt.plot(log_data[\"acc\"])\n",
    "plt.plot(log_data[\"val_acc\"])\n",
    "plt.legend(['Training Accuracy', \"Validation Accuracy\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.plot(log_data[\"loss\"])\n",
    "plt.plot(log_data[\"val_loss\"])\n",
    "plt.legend(['Training Loss', \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Dice Coefficient\n",
    "plt.plot(log_data[\"dice_coefficient\"])\n",
    "plt.plot(log_data[\"dice_coefficient\"])\n",
    "plt.legend(['Training Dice Coefficient', \"Validation Dice Coefficient\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Results Over Time\n",
    "\n",
    "Visualize how the results of the model improve over time.\n",
    "\n",
    "TODO: Why do the confusion matrices look broken for epoch 10 and 20?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [1, 10, 30]\n",
    "for epoch in epochs:\n",
    "    print('Epoch', epoch)\n",
    "    model = modelutil.get_epoch_model(MODELS_DIR, MODEL_NAME, epoch,\n",
    "                                      custom_objects={\n",
    "                                          'dice_coefficient_loss': dice_coefficient_loss, \n",
    "#                                           'dice_coefficient_loss': metrics.dice_coefficient_loss, \n",
    "                                          'dice_coefficient2_loss': metrics.dice_coefficient2_loss,\n",
    "#          'weighted_binary_crossentropy_loss': weighted_binary_crossentropy_loss,\n",
    "                                                      'dice_coefficient': metrics.dice_coefficient,\n",
    "                                                      'binary_dice_coefficient': metrics.binary_dice_coefficient})\n",
    "    modelutil.plot_binary_confusion_matrix(model, train_gen)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Masks by Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate full images\n",
    "# train_gen.config(batch_size=1, length=10, num_samples=1, crop_shape=None, flip=None, transpose=None, gray_std=None)\n",
    "\n",
    "epochs = [1, 10, 30]\n",
    "for epoch in epochs:\n",
    "    print('Epoch', epoch)\n",
    "    model = modelutil.get_epoch_model(MODELS_DIR, MODEL_NAME, epoch,\n",
    "                                      custom_objects={\n",
    "#                                           'dice_coefficient_loss': metrics.dice_coefficient_loss, \n",
    "                                          'dice_coefficient_loss': dice_coefficient_loss, \n",
    "                                          'dice_coefficient2_loss': metrics.dice_coefficient2_loss,\n",
    "#          'weighted_binary_crossentropy_loss': weighted_binary_crossentropy_loss,\n",
    "                                                      'dice_coefficient': metrics.dice_coefficient,\n",
    "                                                      'binary_dice_coefficient': metrics.binary_dice_coefficient})\n",
    "    for i in range(len(train_gen)):\n",
    "        print('Sequence', i)\n",
    "        x, y = train_gen[i]\n",
    "        print(x.shape)\n",
    "        for j in range(x.shape[0]): # batch size\n",
    "            print('Input')\n",
    "            display(util.animate_crop(x[j, :, :, :, 0], step=20))\n",
    "            print('True')\n",
    "            display(util.animate_crop(y[j, :, :, :, 0], step=20))\n",
    "            print('predicting...')\n",
    "            y_pred = model.predict_on_batch(x)\n",
    "            y_pred = y_pred > BINARY_MASK_THRESH\n",
    "            print('Predicted')\n",
    "            display(util.animate_crop(y_pred[j, :, :, :, 0], step=20))\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
