{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 26 Coarse Gated Segmentation\n",
    "\n",
    "A small-scale (multiple downsamplings) network computes a sigmoidal mask multiplied to the input.  This is followed by a repeated contracting and expanding residual network like u-net or pyramid pooling network.\n",
    "\n",
    "\n",
    "GPU: Tesla K80 11GB.\n",
    "\n",
    "### Results\n",
    "\n",
    "\n",
    "\n",
    "### To Try\n",
    "\n",
    "- Loss Function\n",
    "    - Try filtering out empty crops from training, so dice or jaccard coefficients are valid.\n",
    "    - Try removing smoothing from numerator of loss function, so there is no way to improve the network on empty patches.\n",
    "- u-net or v-net\n",
    "- spatial pyramid pooling\n",
    "- Use small patches, small batches, batchnorm\n",
    "- making sure my loss functions work.\n",
    "- mean squared error loss\n",
    "- Add dilated convolution stack to end of network (small fov increase).\n",
    "- Using Dropout (try 0.1)\n",
    "- A shallow u-net: Pooling once and taking advantage of the smaller volume to increase channels and layers.  This would lead to a greatly increased fov.  \n",
    "- experiment with downsampling: try stride 2 2x2x2 conv like in v-net, not that they offered much justification for why this was better than the usual stride 2 3x3x3 conv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, \n",
    "                          Concatenate, Add, Multiply,\n",
    "                          GaussianNoise, Dropout, Conv3DTranspose, \n",
    "                         )\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK # xvertseg MetaImage files\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "import preprocessing\n",
    "import datagen\n",
    "import modelutil\n",
    "import xvertseg\n",
    "import augmentation\n",
    "import metrics\n",
    "\n",
    "MODEL_NAME = 'model_26'\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "# DATA_DIR = Path('~/data/2018').expanduser()\n",
    "# UVMMC\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "# xVertSeg\n",
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "PP_XVERTSEG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_MD_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_DIR = PROJECT_DATA_DIR / 'tensorboard'\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_DIR, PP_XVERTSEG_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# I love u autoreload!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = dict()\n",
    "\n",
    "SD = 'seed'\n",
    "VS = 'validation_split'\n",
    "TS = 'test_split'\n",
    "\n",
    "HP[SD] = 25 # random seed for dataset shuffling and splitting.\n",
    "HP[VS] = 0.2 # VALIDATION_SPLIT = 0.2 # 3 samples for validation\n",
    "HP[TS] = 0.134 # 2 samples for test\n",
    "\n",
    "BS = 'batch_size'\n",
    "NB = 'n_batches' # number of batches in an epoch or None for the sensible default\n",
    "EP = 'epochs'\n",
    "MQS = 'max_queue_size'\n",
    "\n",
    "HP[BS] = 1 \n",
    "HP[NB] = 10 # Used to increase epoch size. \n",
    "HP[MQS] = 20\n",
    "HP[EP] = 100\n",
    "\n",
    "PS = 'patch_shape'\n",
    "IS = 'input_shape'\n",
    "BMT = 'binary_mask_thresh'\n",
    "\n",
    "# PATCH_SHAPE = (32, 32, 32)\n",
    "# PATCH_SHAPE = (64, 64, 64) # Used to crop images for training (data augmentation, memory, speed)\n",
    "HP[PS] = (128, 128, 128) # Big.  Good for visualization.\n",
    "# PATCH_SHAPE = None # Full sized images\n",
    "\n",
    "# INPUT_SHAPE = (PATCH_SHAPE + (1,)) # Model input shape adds channel dimension, but not examples dim.\n",
    "HP[IS] = (None, None, None, 1) # Accept variable size volumes/images.\n",
    "\n",
    "HP[BMT] = 0.5 # > threshold = 1. <= thresh = 0.\n",
    "\n",
    "TR = 'transpose'\n",
    "FL = 'flip'\n",
    "GS = 'grey_std'\n",
    "REQUIRE_MASK = 'require_mask'\n",
    "\n",
    "\n",
    "HP[TR] = False\n",
    "HP[FL] = 0.5\n",
    "HP[GS] = 0.01\n",
    "HP[REQUIRE_MASK] = False\n",
    "\n",
    "\n",
    "KS = 'kernel_size'\n",
    "DROPOUT = 'dropout_rate'\n",
    "NOISE = 'noise_rate' # std dev of gaussian noise\n",
    "NC = 'n_c' # number of channels\n",
    "ND = 'n_d' # number of downsamplings\n",
    "NR = 'n_r' # number of residual blocks\n",
    "NBL = 'n_blocks'\n",
    "NDG = 'n_dg' # number of downsamplings for the gate\n",
    "NRG = 'n_rg' # number of residuals at before the end of the gate network\n",
    "NRDG = 'n_rdg' # number of residuals immediately after a downsampling in the gate network\n",
    "MAXC = 'max_c' # maximum number of channels, to keep parameters in check\n",
    "HP[KS] = (3, 3, 3) # (5, 5, 5) # (7, 7, 7)\n",
    "HP[NC] = 16 \n",
    "HP[NDG] = 1 \n",
    "HP[NRG] = 1\n",
    "HP[NRDG] = 1\n",
    "HP[ND] = 1\n",
    "HP[NR] = 1\n",
    "HP[NBL] = 1\n",
    "HP[DROPOUT] = None # 0.1\n",
    "HP[NOISE] = 0.0001\n",
    "\n",
    "LOSS = 'loss'\n",
    "W0 = 'w0'\n",
    "W1 = 'w1'\n",
    "HP[LOSS] = 'smooth_dice_loss'\n",
    "HP[W0] = 1 # binary cross entropy weight for class 0\n",
    "HP[W1] = 100 # weight informed by the 1-to-0 ratio in the training data.\n",
    "\n",
    "MODELS = [\n",
    "    {'id': 'ndg5', 'hp': {**HP, **{}}},\n",
    "    {'id': 'ndg5a', 'hp': {**HP, **{NDG: 4, NRG: 8, NRDG: 2,\n",
    "                                    ND: 3, NR: 2, NBL: 4,\n",
    "                                    MAXC: 64}}},\n",
    "    {'id': 'ndg4', 'hp': {**HP, **{NDG: 4, NRG: 8, NRDG: 2,\n",
    "                                   ND: 3, NR: 2, NBL: 4,\n",
    "                                   MAXC: 64,\n",
    "                                   LOSS: 'rough_dice_loss',\n",
    "                                  }}},\n",
    "    {'id': 'rqmsk', 'hp': {**HP, **{NDG: 4, NRG: 8, NRDG: 2,\n",
    "                                   ND: 3, NR: 2, NBL: 4,\n",
    "                                   MAXC: 64,\n",
    "                                   LOSS: 'smooth_dice_loss',\n",
    "                                   REQUIRE_MASK: True,\n",
    "                                  }}},\n",
    "]\n",
    "\n",
    "md = MODELS[-1]\n",
    "hp = md['hp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_func = lambda: xvertseg.read_xvertseg_metadata(PP_XVERTSEG_MD_PATH)\n",
    "train_gen, val_gen, test_gen = xvertseg.get_xvertseg_datagens(\n",
    "    infos_func, seed=hp[SD], validation_split=hp[VS], test_split=hp[TS])\n",
    "\n",
    "train_gen.config(batch_size=hp[BS], length=hp[NB], crop_shape=hp[PS], flip=hp[FL], \n",
    "                 transpose=hp[TR], gray_std=hp[GS], require_mask=hp[REQUIRE_MASK]).reindex()\n",
    "val_gen.config(batch_size=hp[BS], crop_shape=hp[PS], flip=hp[FL], \n",
    "               transpose=hp[TR], gray_std=hp[GS]).reindex()\n",
    "# val_gen.config(batch_size=1).reindex() # Test full image\n",
    "test_gen.config(batch_size=1).reindex() # Evaluate using full image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, n_c, kernel_size=(3,3,3), activation='relu'):\n",
    "        x_initial = x\n",
    "        x = Conv3D(n_c, kernel_size=kernel_size, padding='same', activation=activation)(x)\n",
    "        x = Add()([x_initial, x])  \n",
    "        return x\n",
    "\n",
    "\n",
    "def residual_pyramid_block(x, n_c=None, max_c=None, n_d=1, n_r=1, kernel_size=(3, 3, 3)):\n",
    "    '''\n",
    "    x is downsampled n_d times, each downsampled layer is convolved n_r times\n",
    "    and then upsampled and merged with the layer above it.\n",
    "    '''\n",
    "    \n",
    "    if n_c is None:\n",
    "        n_c = int(x.shape[-1]) # channels last\n",
    "\n",
    "    # depth 0\n",
    "    xds = {0: x} # skip connection\n",
    "    \n",
    "    def chans(d):\n",
    "        if max_c is not None:\n",
    "            return min(n_c * (2**d), max_c)\n",
    "        else:\n",
    "            return n_c * (2**d) # The usual double channels when you increase depth.\n",
    "        \n",
    "\n",
    "    \n",
    "    # downsample.  u-net is maxpool, conv, conv\n",
    "    for d in range(1, n_d + 1):\n",
    "#         x = AveragePooling3D(padding='same')(x)\n",
    "#         x = MaxPooling3D(padding='same')(x)\n",
    "#         x = Conv3D(n_c, kernel_size=(1, 1, 1), activation='relu')\n",
    "        x = Conv3D(chans(d), kernel_size=kernel_size, strides=(2,2,2), padding='same', \n",
    "                   activation='relu')(x)\n",
    "        xds[d] = x\n",
    "        \n",
    "    # convolve.  u-net is none.\n",
    "    for d in range(1, n_d + 1):\n",
    "        x = xds[d]\n",
    "        for j in range(n_r):\n",
    "            x = residual_block(x, chans(d), kernel_size=kernel_size)    \n",
    "        \n",
    "        xds[d] = x\n",
    "    \n",
    "    # upsample and merge\n",
    "    for d in reversed(range(n_d)):\n",
    "        # upsample and reduce channels to chans(d)\n",
    "        x = xds[d + 1]        \n",
    "        x = Conv3DTranspose(chans(d), kernel_size=kernel_size, strides=(2,2,2),\n",
    "                            padding='same', activation='relu')(x)\n",
    "        # merge\n",
    "        x2 = xds[d]\n",
    "        x = Add()([x, x2])\n",
    "        xds[d] = x\n",
    "\n",
    "    return x  \n",
    "    \n",
    "    \n",
    "def build_model(input_shape, n_c=4, max_c=None, n_blocks=4, n_r=4, n_d=4, n_rg=1, n_dg=4, n_rdg=3, noise=None, \n",
    "                loss='binary_crossentropy', metrics=[], kernel_size=3):\n",
    "    '''\n",
    "    n_rd: number of residual convs after downsampling\n",
    "\n",
    "    returns: Keras model\n",
    "    '''\n",
    "    x_input = Input(shape=input_shape)\n",
    "    x = x_input\n",
    "    \n",
    "    # noise regularization\n",
    "    if noise: \n",
    "        x = GaussianNoise(stddev=noise)(x)\n",
    "\n",
    "    x = Conv3D(n_c, kernel_size=(5, 5, 5), padding='same', activation='relu')(x)\n",
    "    \n",
    "    #\n",
    "    # COARSE GATE\n",
    "    #\n",
    "    \n",
    "    x_init = x # save x for the gated merge\n",
    "    \n",
    "    def chans(d):\n",
    "        if max_c is not None:\n",
    "            print('chans max_c', max_c)\n",
    "            return min(n_c * (2**d), max_c)\n",
    "        else:\n",
    "            return n_c * (2**d) # The usual double channels when you increase depth.\n",
    "        \n",
    "    for i in range(n_dg):\n",
    "        # downsample\n",
    "        n_cd = chans(i+1)\n",
    "        x = Conv3D(n_cd, kernel_size=kernel_size, strides=(2,2,2), padding='same',\n",
    "                   activation='relu')(x)\n",
    "        for j in range(n_rdg):\n",
    "            print('gate downsampling residuals', i, j, n_rdg, n_cd)\n",
    "            x = residual_block(x, n_cd, kernel_size=kernel_size)    \n",
    "\n",
    "    for i in range(n_rg):\n",
    "        print('gate bottom residuals', i, n_rg, chans(n_dg))\n",
    "        x = residual_block(x, chans(n_dg), kernel_size=kernel_size)    \n",
    "        \n",
    "    # coarse sigmoid\n",
    "    x = Conv3D(1, kernel_size=(1, 1, 1), activation='sigmoid')(x)\n",
    "    \n",
    "    # upsample and gate input\n",
    "    x = UpSampling3D(size=(2**n_dg, 2**n_dg, 2**n_dg))(x)\n",
    "    x = Multiply()([x, x_init])\n",
    "\n",
    "    #\n",
    "    # SEGMENTATION\n",
    "    #\n",
    "    \n",
    "    for i in range(n_blocks):\n",
    "        x = residual_pyramid_block(x, n_d=n_d, n_r=n_r, kernel_size=kernel_size)\n",
    "\n",
    "    x = Conv3D(n_c, kernel_size=kernel_size, padding='same', activation='relu')(x)\n",
    "    y = Conv3D(1, kernel_size=(1, 1, 1), activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=y)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'] + metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "# weighted_binary_crossentropy_loss = metrics.weighted_binary_crossentropy_loss_func(w0=W0, w1=W1)\n",
    "if hp[LOSS] == 'rough_dice_loss':\n",
    "    loss = metrics.make_dice_coefficient_loss(smooth_numerator=False, smooth=1e-5)\n",
    "    loss_name = 'dice_coefficient_loss'\n",
    "elif hp[LOSS] == 'smooth_dice_loss':\n",
    "    loss = metrics.make_dice_coefficient_loss(smooth_numerator=True, smooth=1e-5)\n",
    "    loss_name = 'dice_coefficient_loss'\n",
    "elif hp[LOSS] == 'dice_loss':\n",
    "    loss = metrics.dice_coefficient_loss\n",
    "    loss_name = 'dice_coefficient_loss'\n",
    "elif hp[LOSS] == 'dice2_loss':\n",
    "    loss = metrics.dice_coefficient2_loss\n",
    "    loss_name = 'dice_coefficient2_loss'\n",
    "elif hp[LOSS] == 'weighted_binary_crossentropy_loss':\n",
    "    loss = metrics.weighted_binary_crossentropy_loss_func(w0=hp[W0], w1=hp[W1])\n",
    "    loss_name = 'weighted_binary_crossentropy_loss'\n",
    "    \n",
    "model = build_model(input_shape=hp[IS], n_c=hp[NC], max_c=hp[MAXC], n_r=hp[NR], n_d=hp[ND], \n",
    "                    n_blocks=hp[NBL], n_rg=hp[NRG], n_dg=hp[NDG], n_rdg=hp[NRDG],\n",
    "                    noise=hp[NOISE], kernel_size=hp[KS],\n",
    "                    loss=loss,\n",
    "                    metrics=[metrics.dice_coefficient, metrics.binary_dice_coefficient])\n",
    "print(model.summary())\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = MODEL_NAME + '_' + md['id']\n",
    "\n",
    "callbacks = [modelutil.get_tensorboard_callback(TENSORBOARD_DIR, model_name),\n",
    "             modelutil.get_logger_callback(LOG_DIR, model_name),\n",
    "             modelutil.get_checkpoint_callback(MODELS_DIR, model_name),\n",
    "            ]\n",
    "# datagen shuffles every epoch\n",
    "history = model.fit_generator(train_gen, epochs=hp[EP], validation_data=val_gen, \n",
    "                              callbacks=callbacks, max_queue_size=hp[MQS],\n",
    "                              use_multiprocessing=False, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Notes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "coarse gated segmentation\n",
    "hyperparams:\n",
    "{'W0': 1,\n",
    " 'W1': 100,\n",
    " 'batch_size': 1,\n",
    " 'binary_mask_thresh': 0.5,\n",
    " 'dropout_rate': None,\n",
    " 'epochs': 100,\n",
    " 'flip': 0.5,\n",
    " 'grey_std': 0.01,\n",
    " 'input_shape': (None, None, None, 1),\n",
    " 'kernel_size': (3, 3, 3),\n",
    " 'max_c': 64,\n",
    " 'max_queue_size': 20,\n",
    " 'n_batches': 10,\n",
    " 'n_blocks': 4,\n",
    " 'n_c': 16,\n",
    " 'n_d': 3,\n",
    " 'n_dg': 4,\n",
    " 'n_r': 2,\n",
    " 'n_rdg': 2,\n",
    " 'n_rg': 8,\n",
    " 'noise_rate': 0.0001,\n",
    " 'patch_shape': (128, 128, 128),\n",
    " 'seed': 25,\n",
    " 'test_split': 0.134,\n",
    " 'transpose': False,\n",
    " 'validation_split': 0.2}\n",
    "\n",
    "Total params: 8,874,530\n",
    "48s/epoch.  \n",
    "\n",
    "Very similar in performance to the pyramid parsing network.  I'm pretty sure it is in the zero trap, without having looked at any output or ...\n",
    "\n",
    "-----\n",
    "\n",
    "{'loss': 'rough_dice_loss',\n",
    " 'w0': 1,\n",
    " 'w1': 100,\n",
    " 'batch_size': 1,\n",
    " 'binary_mask_thresh': 0.5,\n",
    " 'dropout_rate': None,\n",
    " 'epochs': 100,\n",
    " 'flip': 0.5,\n",
    " 'grey_std': 0.01,\n",
    " 'input_shape': (None, None, None, 1),\n",
    " 'kernel_size': (3, 3, 3),\n",
    " 'max_c': 64,\n",
    " 'max_queue_size': 20,\n",
    " 'n_batches': 10,\n",
    " 'n_blocks': 4,\n",
    " 'n_c': 16,\n",
    " 'n_d': 3,\n",
    " 'n_dg': 4,\n",
    " 'n_r': 2,\n",
    " 'n_rdg': 2,\n",
    " 'n_rg': 8,\n",
    " 'noise_rate': 0.0001,\n",
    " 'patch_shape': (128, 128, 128),\n",
    " 'seed': 25,\n",
    " 'test_split': 0.134,\n",
    " 'transpose': False,\n",
    " 'validation_split': 0.2}\n",
    "Total params: 8,874,530\n",
    "\n",
    "Looks like all the other models with no numerator smoothing in the dice loss.\n",
    "\n",
    "---\n",
    "\n",
    "Add require mask to data generation, s.t. every mask contains some masked pixels.\n",
    "Change loss back to 'smooth_dice_loss'\n",
    "{'batch_size': 1,\n",
    " 'binary_mask_thresh': 0.5,\n",
    " 'dropout_rate': None,\n",
    " 'epochs': 100,\n",
    " 'flip': 0.5,\n",
    " 'grey_std': 0.01,\n",
    " 'input_shape': (None, None, None, 1),\n",
    " 'kernel_size': (3, 3, 3),\n",
    " 'loss': 'smooth_dice_loss',\n",
    " 'max_c': 64,\n",
    " 'max_queue_size': 20,\n",
    " 'n_batches': 10,\n",
    " 'n_blocks': 4,\n",
    " 'n_c': 16,\n",
    " 'n_d': 3,\n",
    " 'n_dg': 4,\n",
    " 'n_r': 2,\n",
    " 'n_rdg': 2,\n",
    " 'n_rg': 8,\n",
    " 'noise_rate': 0.0001,\n",
    " 'patch_shape': (128, 128, 128),\n",
    " 'require_mask': True,\n",
    " 'seed': 25,\n",
    " 'test_split': 0.134,\n",
    " 'transpose': False,\n",
    " 'validation_split': 0.2,\n",
    " 'w0': 1,\n",
    " 'w1': 100}\n",
    "Total params: 8,874,530\n",
    "48s\n",
    "\n",
    "If I have it right, from the dice score training graph for various models, there is ~60-70% chance of getting a blank mask crop.  Certainly born out by all the failed attempts at cropping happening with the require=True.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metrics from the log file\n",
    "# get latest log path\n",
    "log_path = sorted(LOG_DIR.glob(f'{MODEL_NAME}*_log.csv'))[-1]\n",
    "print(log_path)\n",
    "log_data = pd.read_csv(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([log_data[::10], log_data[-1:]]) # every 10th metric and the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy \n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,1.0]) # Show results on 0..1 range\n",
    "plt.plot(log_data[\"acc\"])\n",
    "plt.plot(log_data[\"val_acc\"])\n",
    "plt.legend(['Training Accuracy', \"Validation Accuracy\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.plot(log_data[\"loss\"])\n",
    "plt.plot(log_data[\"val_loss\"])\n",
    "plt.legend(['Training Loss', \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Dice Coefficient\n",
    "plt.plot(log_data[\"dice_coefficient\"])\n",
    "plt.plot(log_data[\"dice_coefficient\"])\n",
    "plt.legend(['Training Dice Coefficient', \"Validation Dice Coefficient\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Results Over Time\n",
    "\n",
    "Visualize how the results of the model improve over time.\n",
    "\n",
    "TODO: Why do the confusion matrices look broken for epoch 10 and 20?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = MODEL_NAME + '_' + md['id']\n",
    "\n",
    "epochs = [100]\n",
    "for epoch in epochs:\n",
    "    print('Epoch', epoch)\n",
    "    model = modelutil.get_epoch_model(MODELS_DIR, model_name, epoch,\n",
    "                                      custom_objects={\n",
    "                                          loss_name: loss\n",
    "                                                      'dice_coefficient': metrics.dice_coefficient,\n",
    "                                                      'binary_dice_coefficient': metrics.binary_dice_coefficient})\n",
    "    modelutil.plot_binary_confusion_matrix(model, train_gen)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Masks by Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate full images\n",
    "# train_gen.config(batch_size=1, length=10, num_samples=1, crop_shape=None, flip=None, transpose=None, gray_std=None)\n",
    "\n",
    "epochs = [1, 10, 30]\n",
    "for epoch in epochs:\n",
    "    print('Epoch', epoch)\n",
    "    model = modelutil.get_epoch_model(MODELS_DIR, MODEL_NAME, epoch,\n",
    "                                      custom_objects={\n",
    "#                                           'dice_coefficient_loss': metrics.dice_coefficient_loss, \n",
    "                                          'dice_coefficient_loss': dice_coefficient_loss, \n",
    "                                          'dice_coefficient2_loss': metrics.dice_coefficient2_loss,\n",
    "#          'weighted_binary_crossentropy_loss': weighted_binary_crossentropy_loss,\n",
    "                                                      'dice_coefficient': metrics.dice_coefficient,\n",
    "                                                      'binary_dice_coefficient': metrics.binary_dice_coefficient})\n",
    "    for i in range(len(train_gen)):\n",
    "        print('Sequence', i)\n",
    "        x, y = train_gen[i]\n",
    "        print(x.shape)\n",
    "        for j in range(x.shape[0]): # batch size\n",
    "            print('Input')\n",
    "            display(util.animate_crop(x[j, :, :, :, 0], step=20))\n",
    "            print('True')\n",
    "            display(util.animate_crop(y[j, :, :, :, 0], step=20))\n",
    "            print('predicting...')\n",
    "            y_pred = model.predict_on_batch(x)\n",
    "            y_pred = y_pred > BINARY_MASK_THRESH\n",
    "            print('Predicted')\n",
    "            display(util.animate_crop(y_pred[j, :, :, :, 0], step=20))\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
