{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 9\n",
    "\n",
    "First fracture prediction model.  Convolutional downsampling, residual blocks, global pooling before class prediction. \n",
    "\n",
    "Batch size 1 to accomodate memory constraints AND different size samples.\n",
    "\n",
    "Model quickly learns to classify everything as non-fracture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, Concatenate, Add)\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "importlib.reload(util)\n",
    "import preprocessing\n",
    "importlib.reload(preprocessing)\n",
    "import datagen\n",
    "importlib.reload(datagen)\n",
    "import modelutil\n",
    "importlib.reload(modelutil)\n",
    "\n",
    "SEED = 0\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1\n",
    "PATCH_SHAPE = (32, 32, 32)\n",
    "\n",
    "MODEL_NAME = 'model_09'\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_LOG_DIR = PROJECT_DATA_DIR / 'tensorboard' / MODEL_NAME\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_LOG_DIR, TMP_DIR, PP_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, val_gen = datagen.get_nifti_fracture_datagens(\n",
    "    preprocessed_metadata_path=PP_MD_PATH, batch_size=BATCH_SIZE, seed=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "\n",
    "Downsampled agressively with strided convolutions to fit in memory.  Residual blocks.  Global pooling at the end to classify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_residual_encoder_decoder_block(x, n_a, n_d=1, use_bn=True):\n",
    "\n",
    "    x = batchnorm_conv_block(x, n_a, use_bn=use_bn)\n",
    "    \n",
    "    if n_d > 0:\n",
    "        x_e = x # shape: (32, 32, 32, 16)\n",
    "        x_e = MaxPooling3D(padding='same')(x_e) # shape: (16, 16, 16, 16)\n",
    "        x_e = build_residual_encoder_decoder_block(x_e, n_a, n_d - 1, use_bn=use_bn) # recursive call\n",
    "        x_d = UpSampling3D()(x_e) # shape (32, 32, 32, 16)\n",
    "        x = Concatenate()([x, x_d]) # residual join.  shape (32, 32, 32, 32)\n",
    "        x = batchnorm_conv_block(x, n_a, use_bn=use_bn)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def batchnorm_conv_block(x, n_a, use_bn=True):\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), padding='same', activation='relu')(x) # shape: (32, 32, 32, 1) = 32768\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_residual_block(x, n_a, n_l=1, use_bn=True):\n",
    "    '''\n",
    "    n_l: number of layers/convolutions in the residual path.\n",
    "    '''\n",
    "    x_r = x\n",
    "    for i in range(n_l):\n",
    "        x_r = batchnorm_conv_block(x_r, n_a, use_bn=use_bn)\n",
    "        \n",
    "    x = Add()([x, x_r])  \n",
    "    return x\n",
    "\n",
    "\n",
    "def build_downsampling_conv_block(x, n_a, use_bn=True):\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Conv3D(n_a, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same', activation='relu')(x) \n",
    "    return x\n",
    "    \n",
    "    \n",
    "def build_model(input_shape, n_a=16, n_r=2, n_d=4, use_bn=True):\n",
    "    '''\n",
    "    3D convolutional autoencoder that treats u-net architecture as a residual block.\n",
    "    \n",
    "    1 poolings reduce input from shape to shape/2, which in 3d is 1/8th the size of the original shape,\n",
    "    a very respectable compression factor.\n",
    "    '''\n",
    "\n",
    "    x_input = Input(shape=input_shape)\n",
    "    x = x_input\n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*2, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*2, n_l=1, use_bn=use_bn) \n",
    "\n",
    "    # u-net\n",
    "#    x = build_residual_encoder_decoder_block(x, n_a=(n_a//2), n_d=n_d)\n",
    "    \n",
    "    # upsample for autoencoder\n",
    "#     x_ae = UpSampling3D()(x)\n",
    "#     x_ae = batchnorm_conv_block(x_ae, n_a=n_a)\n",
    "#     y_ae = Conv3D(1, kernel_size=(3, 3, 3), padding='same', activation='sigmoid')(x)\n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*4, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*4, n_l=1, use_bn=use_bn) \n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*8, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*8, n_l=1, use_bn=use_bn) \n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*16, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*16, n_l=1, use_bn=use_bn) \n",
    "\n",
    "    x = build_downsampling_conv_block(x, n_a=n_a*32, use_bn=use_bn)\n",
    "    x = build_residual_block(x, n_a=n_a*32, n_l=1, use_bn=use_bn) \n",
    "    x = build_residual_block(x, n_a=n_a*32, n_l=1, use_bn=use_bn)\n",
    "     \n",
    "    # pool and predict\n",
    "    x = GlobalMaxPooling3D()(x)\n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Dense(n_a*16, activation='relu')(x)\n",
    "    y_frac = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=y_frac)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=(None, None, None, 1,), n_a=4, n_r=4, n_d=4, use_bn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model\n",
    "\n",
    "- Add callbacks to save model every 20 epochs and to log performance stats every epoch, so we have the results saved somewhere for charting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history, log_path = modelutil.train_model(\n",
    "#     model, train_gen, val_gen, epochs=40, batch_size=BATCH_SIZE, models_dir=MODELS_DIR, model_name=MODEL_NAME, \n",
    "#     log_dir=LOG_DIR, tensorboard_log_dir=TENSORBOARD_LOG_DIR, max_queue_size=20, use_multiprocessing=True, \n",
    "#     class_weight={0: 1, 1: 5})\n",
    "history, log_path = modelutil.train_model_epoch(train_gen, val_gen, epoch=40, epochs=200, batch_size=BATCH_SIZE, models_dir=MODELS_DIR, model_name=MODEL_NAME, \n",
    "    log_dir=LOG_DIR, tensorboard_log_dir=TENSORBOARD_LOG_DIR, max_queue_size=20, use_multiprocessing=True, \n",
    "    class_weight={0: 1, 1: 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metrics from the log file\n",
    "# log_path = LOG_DIR / (model_name + '_2018-04-26T17:29:02.902740_log.csv')\n",
    "# log_path = Path('/data2/uvm_deep_learning_project/log/model_09_2018-04-28T02:02:18.169239_log.csv')\n",
    "metrics = pd.read_csv(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([metrics[::10], metrics[-1:]])) # every 10th metric and the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy \n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,1.0]) # Show results on 0..1 range\n",
    "plt.plot(metrics[\"acc\"])\n",
    "plt.plot(metrics[\"val_acc\"])\n",
    "plt.legend(['Training Accuracy', \"Validation Accuracy\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.plot(metrics[\"loss\"])\n",
    "plt.plot(metrics[\"val_loss\"])\n",
    "plt.legend(['Training Loss', \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Results Over Time\n",
    "\n",
    "Visualize how the results of the model improve over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix_by_epochs()\n",
    "modelutil.confusion_matrix_by_epochs(MODELS_DIR, MODEL_NAME, [1, 10, 200], val_gen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
