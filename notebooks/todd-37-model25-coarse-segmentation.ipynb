{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 25 Coarse Segmentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GPU: Tesla K80 11GB.\n",
    "\n",
    "### Results\n",
    "\n",
    "\n",
    "\n",
    "### To Try\n",
    "\n",
    "- Loss Function\n",
    "    - Try filtering out empty crops from training, so dice or jaccard coefficients are valid.\n",
    "    - Try removing smoothing from numerator of loss function, so there is no way to improve the network on empty patches.\n",
    "- u-net or v-net\n",
    "- spatial pyramid pooling\n",
    "- Use small patches, small batches, batchnorm\n",
    "- making sure my loss functions work.\n",
    "- mean squared error loss\n",
    "- Add dilated convolution stack to end of network (small fov increase).\n",
    "- Using Dropout (try 0.1)\n",
    "- A shallow u-net: Pooling once and taking advantage of the smaller volume to increase channels and layers.  This would lead to a greatly increased fov.  \n",
    "- experiment with downsampling: try stride 2 2x2x2 conv like in v-net, not that they offered much justification for why this was better than the usual stride 2 3x3x3 conv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, \n",
    "                          Concatenate, Add, Multiply,\n",
    "                          GaussianNoise, Dropout, Conv3DTranspose, \n",
    "                         )\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK # xvertseg MetaImage files\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "import preprocessing\n",
    "import datagen\n",
    "import modelutil\n",
    "import xvertseg\n",
    "import augmentation\n",
    "import metrics\n",
    "\n",
    "MODEL_NAME = 'model_25'\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "# DATA_DIR = Path('~/data/2018').expanduser()\n",
    "# UVMMC\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "# xVertSeg\n",
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "PP_XVERTSEG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_MD_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_DIR = PROJECT_DATA_DIR / 'tensorboard'\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_DIR, PP_XVERTSEG_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# I love u autoreload!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 25 # random seed for dataset shuffling and splitting.\n",
    "VALIDATION_SPLIT = 0.2 # 3 samples for validation\n",
    "TEST_SPLIT = 0.134 # 2 samples for test\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "N_BATCHES = 10 # The number of batches per epoch or None\n",
    "NUM_SAMPLES = 1 # Show each image num_samples times per epoch. Ignored if N_BATCHES is set.\n",
    "MAX_QUEUE_SIZE = 20\n",
    "EPOCHS = 100\n",
    "\n",
    "# PATCH_SHAPE = (32, 32, 32)\n",
    "# PATCH_SHAPE = (64, 64, 64) # Used to crop images for training (data augmentation, memory, speed)\n",
    "PATCH_SHAPE = (128, 128, 128) # Big.  Good for visualization.\n",
    "# PATCH_SHAPE = None # Full sized images\n",
    "\n",
    "# INPUT_SHAPE = (PATCH_SHAPE + (1,)) # Model input shape adds channel dimension, but not examples dim.\n",
    "INPUT_SHAPE = (None, None, None, 1) # Accept variable size volumes/images.\n",
    "\n",
    "BINARY_MASK_THRESH = 0.5 # > threshold = 1. <= thresh = 0.\n",
    "\n",
    "TRANSPOSE = False\n",
    "FLIP = 0.5\n",
    "GRAY_STD = 0.01\n",
    "\n",
    "# Visualize model using the first set of hyperparams\n",
    "# KERNEL_SIZE = (7, 7, 7)\n",
    "# KERNEL_SIZE = (5, 5, 5)\n",
    "KERNEL_SIZE = (3, 3, 3)\n",
    "N_A = 16 # number of channels\n",
    "N_R = 16 # number of residual blocks\n",
    "N_D = 4\n",
    "N_RD = 2\n",
    "DROPOUT = None # 0.1\n",
    "NOISE = 0.0001\n",
    "\n",
    "W0 = 1 # binary cross entropy weight for class 0\n",
    "W1 = 100 # weight informed by the 1-to-0 ratio in the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_func = lambda: xvertseg.read_xvertseg_metadata(PP_XVERTSEG_MD_PATH)\n",
    "train_gen, val_gen, test_gen = xvertseg.get_xvertseg_datagens(\n",
    "    infos_func, seed=SEED, validation_split=VALIDATION_SPLIT, test_split=TEST_SPLIT)\n",
    "\n",
    "train_gen.config(batch_size=BATCH_SIZE, length=N_BATCHES, crop_shape=PATCH_SHAPE, flip=FLIP, \n",
    "                 transpose=TRANSPOSE, gray_std=GRAY_STD, num_samples=NUM_SAMPLES).reindex()\n",
    "val_gen.config(batch_size=BATCH_SIZE, crop_shape=PATCH_SHAPE, flip=FLIP, \n",
    "               transpose=TRANSPOSE, gray_std=GRAY_STD).reindex()\n",
    "# val_gen.config(batch_size=1).reindex() # Test full image\n",
    "test_gen.config(batch_size=1).reindex() # Evaluate using full image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, n_a, kernel_size=(3,3,3), activation='relu'):\n",
    "        x_initial = x\n",
    "        x = Conv3D(n_a, kernel_size=kernel_size, padding='same', activation=activation)(x)\n",
    "        x = Add()([x_initial, x])  \n",
    "        return x\n",
    "    \n",
    "    \n",
    "def build_model(input_shape, n_a=4, n_r=4, n_d=4, n_rd=2, noise=None, loss='binary_crossentropy', metrics=[],\n",
    "                kernel_size=3):\n",
    "    '''\n",
    "    Input conv 2 times.  16 channels. 33V = 1 + (16 * 2)  Fov: 5\n",
    "downconv residual conv 2 times.  64 channels.  32V = V/8 * (64 * 2 * 2).  Fov: 5 + 8\n",
    "Downconv residual conv 32 times. 128 channels.  Fov 269 = 13 + 256.  128V = V/64 * (128 * 32 * 2)\n",
    "Upconv concat residual conv 2 times.  64 channels.  Fov = 285 = 269 + 16.  56V = V/8 * (64 + 128 + (64 * 2 * 2))\n",
    "Upconv concat conv conv conv 16 channels.  Fov 289 = 285 + 4.  67V = 16 + 32 + 16 * 2 + 1\n",
    "\n",
    "    n_rd: number of residual convs after downsampling\n",
    "\n",
    "    returns: Keras model\n",
    "    '''\n",
    "\n",
    "    \n",
    "    x_input = Input(shape=input_shape)\n",
    "    x = x_input\n",
    "    \n",
    "    # noise regularization\n",
    "    if noise: \n",
    "        x = GaussianNoise(stddev=noise)(x)\n",
    "\n",
    "    x = Conv3D(n_a, kernel_size=kernel_size, padding='same', activation='relu')(x)\n",
    "    x = Conv3D(n_a, kernel_size=kernel_size, padding='same', activation='relu')(x)\n",
    "    \n",
    "    x_init = x # save x for the gated merge\n",
    "    \n",
    "    def n_ad(n_a, d):\n",
    "        # d: scale depth\n",
    "        return n_a * min(2**d, 4)\n",
    "        \n",
    "    for i in range(n_d):\n",
    "        # downsample\n",
    "        x = Conv3D(n_ad(n_a, i+1), kernel_size=kernel_size, strides=(2,2,2), padding='same', activation='relu')(x)\n",
    "        for j in range(n_rd):\n",
    "            x = residual_block(x, n_ad(n_a, i+1), kernel_size=kernel_size)    \n",
    "\n",
    "    for i in range(n_r):\n",
    "        x = residual_block(x, n_ad(n_a, n_d), kernel_size=kernel_size)    \n",
    "        \n",
    "    # coarsely gate and upsample\n",
    "    x = Conv3D(1, kernel_size=(1, 1, 1), activation='sigmoid')(x)\n",
    "    y = UpSampling3D(size=(16, 16, 16))(x)\n",
    "        \n",
    "# Old ending.  Double sigmoid?  Oops.\n",
    "#     # upsample coarsely and gate\n",
    "#     x = Conv3D(n_a, kernel_size=(1, 1, 1), activation='sigmoid')(x)\n",
    "#     x = UpSampling3D(size=(16, 16, 16))(x)\n",
    "    \n",
    "#     # output\n",
    "#     y = Conv3D(1, kernel_size=(1, 1, 1), activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=y)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'] + metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "# weighted_binary_crossentropy_loss = metrics.weighted_binary_crossentropy_loss_func(w0=W0, w1=W1)\n",
    "# dice_coefficient_loss = metrics.make_dice_coefficient_loss(smooth_numerator=True, smooth=1e-5)\n",
    "\n",
    "model = build_model(input_shape=INPUT_SHAPE, n_a=N_A, n_r=N_R, n_d=N_D, n_rd=N_RD,\n",
    "                    noise=NOISE, \n",
    "#                     loss=dice_coefficient_loss,\n",
    "#                     loss='binary_crossentropy',\n",
    "#                     loss=metrics.dice_coefficient_loss,\n",
    "                    loss=metrics.dice_coefficient2_loss,\n",
    "#                     loss=weighted_binary_crossentropy_loss,\n",
    "                    metrics=[metrics.dice_coefficient, metrics.binary_dice_coefficient],\n",
    "                    kernel_size=KERNEL_SIZE)\n",
    "print(model.summary())\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [modelutil.get_tensorboard_callback(TENSORBOARD_DIR, MODEL_NAME),\n",
    "             modelutil.get_logger_callback(LOG_DIR, MODEL_NAME),\n",
    "             modelutil.get_checkpoint_callback(MODELS_DIR, MODEL_NAME),\n",
    "            ]\n",
    "# datagen shuffles every epoch\n",
    "history = model.fit_generator(train_gen, epochs=EPOCHS, validation_data=val_gen, \n",
    "                              callbacks=callbacks, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                              use_multiprocessing=False, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Notes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "coarse segmentation \n",
    "n_a = 16, n_r = 16, for d1, d2, d3, d4, n_a is n_a*2, n_a*4, n_a*4, n_a*4.\n",
    "loss: metrics.dice_coefficient2_loss\n",
    "batch size 1. \n",
    "Total params: 2,567,441\n",
    "Total volume: \n",
    "FOV >256 (n_r * 8)\n",
    "17s/epoch\n",
    "\n",
    "Training loss hovering around 0.05 most of the time.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Noise: 0.0001.  Loss hovered around 0.06 most of the time.\n",
    "17s/epoch\n",
    "\n",
    "---\n",
    "\n",
    "Noise: 0.0002\n",
    "17s/epoch\n",
    "Loss on the tensorboard graph oscilated around 0.065\n",
    "\n",
    "The confusion matrix shows the model is only predicting zeros.  Sad face.\n",
    "\n",
    "---\n",
    "\n",
    "n_d = 4, Noise: 0.0001 \n",
    "Total params: 2,787,761  <- a few more params b/c rewrote code to be more abstract but added a couple convs to lowest layer.\n",
    "17s\n",
    "Started off with decent dice score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metrics from the log file\n",
    "# get latest log path\n",
    "log_path = sorted(LOG_DIR.glob(f'{MODEL_NAME}*_log.csv'))[-1]\n",
    "print(log_path)\n",
    "log_data = pd.read_csv(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([log_data[::10], log_data[-1:]]) # every 10th metric and the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy \n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,1.0]) # Show results on 0..1 range\n",
    "plt.plot(log_data[\"acc\"])\n",
    "plt.plot(log_data[\"val_acc\"])\n",
    "plt.legend(['Training Accuracy', \"Validation Accuracy\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.plot(log_data[\"loss\"])\n",
    "plt.plot(log_data[\"val_loss\"])\n",
    "plt.legend(['Training Loss', \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Dice Coefficient\n",
    "plt.plot(log_data[\"dice_coefficient\"])\n",
    "plt.plot(log_data[\"dice_coefficient\"])\n",
    "plt.legend(['Training Dice Coefficient', \"Validation Dice Coefficient\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Results Over Time\n",
    "\n",
    "Visualize how the results of the model improve over time.\n",
    "\n",
    "TODO: Why do the confusion matrices look broken for epoch 10 and 20?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [100]\n",
    "for epoch in epochs:\n",
    "    print('Epoch', epoch)\n",
    "    model = modelutil.get_epoch_model(MODELS_DIR, MODEL_NAME, epoch,\n",
    "                                      custom_objects={\n",
    "#                                           'dice_coefficient_loss': dice_coefficient_loss, \n",
    "#                                           'dice_coefficient_loss': metrics.dice_coefficient_loss, \n",
    "                                          'dice_coefficient2_loss': metrics.dice_coefficient2_loss,\n",
    "#          'weighted_binary_crossentropy_loss': weighted_binary_crossentropy_loss,\n",
    "                                                      'dice_coefficient': metrics.dice_coefficient,\n",
    "                                                      'binary_dice_coefficient': metrics.binary_dice_coefficient})\n",
    "    modelutil.plot_binary_confusion_matrix(model, train_gen)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Masks by Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate full images\n",
    "# train_gen.config(batch_size=1, length=10, num_samples=1, crop_shape=None, flip=None, transpose=None, gray_std=None)\n",
    "\n",
    "epochs = [1, 10, 30]\n",
    "for epoch in epochs:\n",
    "    print('Epoch', epoch)\n",
    "    model = modelutil.get_epoch_model(MODELS_DIR, MODEL_NAME, epoch,\n",
    "                                      custom_objects={\n",
    "#                                           'dice_coefficient_loss': metrics.dice_coefficient_loss, \n",
    "                                          'dice_coefficient_loss': dice_coefficient_loss, \n",
    "                                          'dice_coefficient2_loss': metrics.dice_coefficient2_loss,\n",
    "#          'weighted_binary_crossentropy_loss': weighted_binary_crossentropy_loss,\n",
    "                                                      'dice_coefficient': metrics.dice_coefficient,\n",
    "                                                      'binary_dice_coefficient': metrics.binary_dice_coefficient})\n",
    "    for i in range(len(train_gen)):\n",
    "        print('Sequence', i)\n",
    "        x, y = train_gen[i]\n",
    "        print(x.shape)\n",
    "        for j in range(x.shape[0]): # batch size\n",
    "            print('Input')\n",
    "            display(util.animate_crop(x[j, :, :, :, 0], step=20))\n",
    "            print('True')\n",
    "            display(util.animate_crop(y[j, :, :, :, 0], step=20))\n",
    "            print('predicting...')\n",
    "            y_pred = model.predict_on_batch(x)\n",
    "            y_pred = y_pred > BINARY_MASK_THRESH\n",
    "            print('Predicted')\n",
    "            display(util.animate_crop(y_pred[j, :, :, :, 0], step=20))\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
