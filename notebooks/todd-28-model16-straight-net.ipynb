{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 16 Straight Net\n",
    "\n",
    "This is the low baseline control.  A convolutional network that starts from the input and ends at the output.  No downsampling!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, Concatenate, Add,\n",
    "                          GaussianNoise, Dropout\n",
    "                         )\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK # xvertseg MetaImage files\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "import preprocessing\n",
    "import datagen\n",
    "import modelutil\n",
    "import xvertseg\n",
    "import augmentation\n",
    "\n",
    "MODEL_NAME = 'model_16'\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "# DATA_DIR = Path('~/data/2018').expanduser()\n",
    "# UVMMC\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "# xVertSeg\n",
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "PP_XVERTSEG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_MD_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_DIR = PROJECT_DATA_DIR / 'tensorboard'\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_DIR, PP_XVERTSEG_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# I love u autoreload!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, n_a=4, n_l=8, dropout=None, noise=None):\n",
    "    '''\n",
    "    3D convolutional straight convolutional segmenter.\n",
    "    \n",
    "    dropout: proportion of activation of input to drop out. 0.0 to 1.0\n",
    "    noise: std dev of noise added to input activation.\n",
    "    returns: model\n",
    "    '''\n",
    "\n",
    "    x_input = Input(shape=input_shape)\n",
    "    x = x_input\n",
    "    \n",
    "    # noise regularization\n",
    "    if noise: \n",
    "        x = GaussianNoise(stddev=noise)(x)\n",
    "\n",
    "    for i in range(n_l):\n",
    "        x = Conv3D(n_a, kernel_size=(5, 5, 5), padding='same', activation='relu')(x)\n",
    "\n",
    "    y = Conv3D(1, kernel_size=(1, 1, 1), activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=y)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "MAX_QUEUE_SIZE = 10\n",
    "EPOCHS = 100\n",
    "\n",
    "SEED = 25 # random seed\n",
    "\n",
    "PATCH_SHAPE = (32, 32, 32)\n",
    "# PATCH_SHAPE = (64, 64, 64)\n",
    "PATCH_SHAPE = (128, 128, 128) # good for visualization.\n",
    "VALIDATION_SPLIT=0.2 # 3 samples for validation\n",
    "TEST_SPLIT=0.134 # 2 samples for test\n",
    "FLIP = 0.5\n",
    "TRANSPOSE = True\n",
    "GRAY_STD = 0.01\n",
    "\n",
    "# Visualize model using the first set of hyperparams\n",
    "N_A=4 # number of channels\n",
    "N_L=0 # number of repeated layers\n",
    "DROPOUT=None\n",
    "NOISE=0.0015\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_func = lambda: xvertseg.read_xvertseg_metadata(PP_XVERTSEG_MD_PATH)\n",
    "train_gen, val_gen, test_gen = xvertseg.get_xvertseg_datagens(\n",
    "    infos_func, validation_split=VALIDATION_SPLIT, test_split=TEST_SPLIT)\n",
    "\n",
    "train_gen.config(batch_size=BATCH_SIZE, crop_shape=PATCH_SHAPE, flip=FLIP, \n",
    "                 transpose=TRANSPOSE, gray_std=GRAY_STD)\n",
    "val_gen.config(batch_size=BATCH_SIZE, crop_shape=PATCH_SHAPE, flip=FLIP, \n",
    "               transpose=TRANSPOSE, gray_std=GRAY_STD)\n",
    "test_gen.config(batch_size=BATCH_SIZE, crop_shape=PATCH_SHAPE, flip=FLIP, \n",
    "                transpose=TRANSPOSE, gray_std=GRAY_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=PATCH_SHAPE + (1,), n_a=N_A, n_l=N_L, \n",
    "                    dropout=DROPOUT, noise=NOISE)\n",
    "print(model.summary())\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [modelutil.get_tensorboard_callback(TENSORBOARD_DIR, MODEL_NAME),\n",
    "             modelutil.get_logger_callback(LOG_DIR, MODEL_NAME),\n",
    "             modelutil.get_checkpoint_callback(MODELS_DIR, MODEL_NAME),\n",
    "            ]\n",
    "history = model.fit_generator(train_gen, epochs=EPOCHS, validation_data=val_gen, \n",
    "                              callbacks=callbacks, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                              use_multiprocessing=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The classes need to be balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=PATCH_SHAPE + (1,), n_a=N_A, n_l=N_L, \n",
    "                    dropout=DROPOUT, noise=NOISE)\n",
    "# CLASS_WEIGHT = {0: 1, 1: 10000} # Does not work in 3d images.\n",
    "EPOCHS=20\n",
    "history = model.fit_generator(train_gen, epochs=EPOCHS, validation_data=val_gen, \n",
    "                              callbacks=callbacks, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                              use_multiprocessing=False, \n",
    "#                              class_weight=CLASS_WEIGHT,\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
