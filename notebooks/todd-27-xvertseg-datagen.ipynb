{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xVertSeg Data Generation\n",
    "\n",
    "For training and evaluation of a binary image segmentation algorithm, we want input of size mxnxnxnx1 and output of size (m, n, n, n, 1).  1 channel.  m examples.  3d volume.  For semantic image segmentation, we want output of size (m, n, n, n, 6) for the one-hot encoded vector of output categories.  xVertSeg also has 2 categorical outcomes.\n",
    "\n",
    "It would be nice to configure the datagen to sample multiple patches from an image.  That might speed training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import keras\n",
    "from keras.layers import (Dense, SimpleRNN, Input, Conv1D, \n",
    "                          LSTM, GRU, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,\n",
    "                          Conv3D, UpSampling3D, BatchNormalization, Concatenate, Add,\n",
    "                          GaussianNoise, Dropout\n",
    "                         )\n",
    "from keras.models import Model\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import projd\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import shutil\n",
    "import SimpleITK # xvertseg MetaImage files\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt # data viz\n",
    "import seaborn as sns # data viz\n",
    "\n",
    "import imageio # display animated volumes\n",
    "from IPython.display import Image # display animated volumes\n",
    "\n",
    "from IPython.display import SVG # visualize model\n",
    "from keras.utils.vis_utils import model_to_dot # visualize model\n",
    "\n",
    "# for importing local code\n",
    "src_dir = str(Path(projd.cwd_token_dir('notebooks')) / 'src') # $PROJECT_ROOT/src\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "import util\n",
    "import preprocessing\n",
    "import datagen\n",
    "import modelutil\n",
    "import xvertseg\n",
    "import augmentation\n",
    "\n",
    "\n",
    "# MODEL_NAME = 'model_15'\n",
    "SEED = 25 # random seed\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SHAPE = (32, 32, 32)\n",
    "# PATCH_SHAPE = (64, 64, 64)\n",
    "PATCH_SHAPE = (128, 128, 128) # good for visualization.\n",
    "VALIDATION_SPLIT = 0.25\n",
    "\n",
    "DATA_DIR = Path('/data2').expanduser()\n",
    "# DATA_DIR = Path('~/data/2018').expanduser()\n",
    "# UVMMC\n",
    "NORMAL_SCANS_DIR = DATA_DIR / 'uvmmc/nifti_normals'\n",
    "PROJECT_DATA_DIR = DATA_DIR / 'uvm_deep_learning_project'\n",
    "PP_IMG_DIR = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed' # preprocessed scans dir\n",
    "PP_MD_PATH = PROJECT_DATA_DIR / 'uvmmc' / 'preprocessed_metadata.pkl'\n",
    "# xVertSeg\n",
    "XVERTSEG_DIR = DATA_DIR / 'xVertSeg.v1'\n",
    "PP_XVERTSEG_DIR = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed' # preprocessed scans dir\n",
    "PP_XVERTSEG_MD_PATH = PROJECT_DATA_DIR / 'xVertSeg.v1' / 'preprocessed_metadata.pkl'\n",
    "\n",
    "\n",
    "MODELS_DIR = PROJECT_DATA_DIR / 'models'\n",
    "LOG_DIR = PROJECT_DATA_DIR / 'log'\n",
    "TENSORBOARD_LOG_DIR = PROJECT_DATA_DIR / 'tensorboard'\n",
    "TMP_DIR = DATA_DIR / 'tmp'\n",
    "\n",
    "for d in [DATA_DIR, NORMAL_SCANS_DIR, PROJECT_DATA_DIR, PP_IMG_DIR, MODELS_DIR, LOG_DIR, \n",
    "          TENSORBOARD_LOG_DIR, TMP_DIR, PP_MD_PATH.parent, PP_XVERTSEG_DIR, PP_XVERTSEG_MD_PATH.parent]:\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True)\n",
    "        \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# I love u autoreload!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'id': range(1, 26),\n",
    "#     'pp_image_path': [Path(f'image{i:03}.mhd') for i in range(1, 26)],\n",
    "#     'pp_mask_path': [Path(f'mask{i:03}.mhd') for i in range(1, 16)] + ([np.nan] * 10),\n",
    "# })\n",
    "# infos_func = lambda: df\n",
    "\n",
    "infos_func = lambda: xvertseg.read_xvertseg_metadata(PP_XVERTSEG_MD_PATH)\n",
    "train, val, test = xvertseg.get_xvertseg_datagens(\n",
    "    infos_func, seed=SEED, validation_split=0.2, test_split=0.134)\n",
    "train.config(batch_size=1, crop_shape=PATCH_SHAPE, flip=0.5, transpose=True, gray_std=0.5, gray_disco=True)\n",
    "# no crop shape and consequently, no transpose.\n",
    "# train.config(crop_shape=None, flip=0.5, transpose=False, gray_std=0.05, gray_disco=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gray_std=0.5 and gray_disco=True looks so cool with the transpose=True!\n",
    "print('train size:', len(train))\n",
    "for i in range(len(train)):\n",
    "    x, y = train[i]\n",
    "    print('y dtype', y.dtype)\n",
    "    print(x.shape)\n",
    "    display(util.animate_crop(x[0, :, :, :, 0], step=20))\n",
    "    display(util.animate_crop(y[0, :, :, :, 0], step=20))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Proportion of Ones in Binary Mask\n",
    "\n",
    "This is used to guide the weighting of classes in the loss function for binary segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gray_std=0.5 and gray_disco=True looks so cool with the transpose=True!\n",
    "zeros = 0\n",
    "ones = 0\n",
    "others = 0\n",
    "train.config(crop_shape=PATCH_SHAPE, transpose=None, flip=None, gray_std=None)\n",
    "for i in range(len(train)):\n",
    "    x, y = train[i]\n",
    "    zeros += np.sum(y == 0)\n",
    "    ones += np.sum(y == 1)\n",
    "    others += np.sum((y != 0) & (y != 1))\n",
    "print('zeros, ones, others:', zeros, ones, others)\n",
    "print('proportion of zeros:', zeros / (zeros + ones + others))\n",
    "print('proportion of ones:', ones / (zeros + ones + others))\n",
    "print('proportion of others:', others / (zeros + ones + others))\n",
    "print('zeros-to-ones ratio:', zeros / ones)\n",
    "print('ones-to-zeros ratio:', ones / zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Whole image.  10 training samples, seed of 25\n",
    "```\n",
    "zeros, ones, others: 558443731 3017212 0\n",
    "proportion of zeros: 0.9946261408961442\n",
    "proportion of ones: 0.005373859103855778\n",
    "proportion of others: 0.0\n",
    "zeros-to-ones ratio: 185.08601019749358\n",
    "ones-to-zeros ratio: 0.005402893492236194\n",
    "```\n",
    "\n",
    "Ran a couple times before setting seed.  Also saw a zeros-to-ones ratio of 162 and 194.\n",
    "\n",
    "Random crop for each image produces varied results.\n",
    "```\n",
    "zeros-to-ones ratio: 187.70820285786272\n",
    "zeros-to-ones ratio: 39.10471985144927\n",
    "zeros-to-ones ratio: 52.257486489780995\n",
    "zeros-to-ones ratio: 149.27099843792544\n",
    "zeros-to-ones ratio: 24.490191788547627\n",
    "zeros-to-ones ratio: 212.60277042167448\n",
    "```\n",
    "It makes sense that the mean would be less than the whole picture mean, since the probability of pixels near the edge (which are typically 0/black) being in a crop are less than central pixel b/c of the way cropping and uniform sampling interact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `num_samples` Feature\n",
    "\n",
    "Use `num_samples` to increase epoch size.  Currently images are randomized and samples can be random crops, but multiple samples for the same image come out one after the other (to avoid image reloading).  Not ideal from a stochastic perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'id': range(1, 26),\n",
    "#     'pp_image_path': [Path(f'image{i:03}.mhd') for i in range(1, 26)],\n",
    "#     'pp_mask_path': [Path(f'mask{i:03}.mhd') for i in range(1, 16)] + ([np.nan] * 10),\n",
    "# })\n",
    "# infos_func = lambda: df\n",
    "\n",
    "# no crop shape and consequently, no transpose.\n",
    "# train.config(crop_shape=None, flip=0.5, transpose=False, gray_std=0.05, gray_disco=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.config(batch_size=3, shuffle=True, length=None, crop_shape=(32, 32, 32), num_samples=2, \n",
    "             gray_std=None, transpose=None, flip=None).reindex()\n",
    "\n",
    "# The gray_std=0.5 and gray_disco=True looks so cool with the transpose=True!\n",
    "print('train size:', len(train))\n",
    "print('batch size:', train.batch_size)\n",
    "print('num_samples:', train.num_samples)\n",
    "for i in range(len(train)):\n",
    "    x, y = train[i]\n",
    "    print(x.shape)\n",
    "    for j in range(x.shape[0]): # batch size\n",
    "        display(util.animate_crop(x[j, :, :, :, 0], step=20))\n",
    "        display(util.animate_crop(y[j, :, :, :, 0], step=20))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test shuffled_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.config(length=None, batch_size=1, shuffle=True, num_samples=1)\n",
    "print(train._shuffle())\n",
    "print(train._shuffle())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random info indices for length 15 sequence\n",
    "train.config(length=15, batch_size=1, shuffle=True, num_samples=1)\n",
    "print(train._shuffle())\n",
    "print(train._shuffle())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length < len(infos)\n",
    "train.config(length=5, batch_size=1, shuffle=True, num_samples=1)\n",
    "print(train._shuffle())\n",
    "print(train._shuffle())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that number of indices is the product of batch_size and length\n",
    "train.config(length=5, batch_size=4, shuffle=True, num_samples=1)\n",
    "print(train._shuffle())\n",
    "print(train._shuffle())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle = False iterates through infos in order\n",
    "train.config(length=15, batch_size=1, shuffle=False, num_samples=1)\n",
    "print(train._shuffle())\n",
    "print(train._shuffle())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `length` Datagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.config(length=15, batch_size=1, shuffle=True, num_samples=1).reindex()\n",
    "print('train size:', len(train))\n",
    "for i in range(len(train)):\n",
    "    x, y = train[i]\n",
    "    print('y dtype', y.dtype)\n",
    "    print(x.shape)\n",
    "    display(util.animate_crop(x[0, :, :, :, 0], step=20))\n",
    "    display(util.animate_crop(y[0, :, :, :, 0], step=20))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
